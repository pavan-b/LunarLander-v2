{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update pyglet library\n",
    "# !pip install pyglet==1.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from gym.wrappers import Monitor\n",
    "import gym\n",
    "import pylab\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from collections import deque\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory_model = 'save_model'\n",
    "directory_graph = 'save_graph'\n",
    "\n",
    "#directory = 'save_graph'\n",
    "if not os.path.exists(directory_model):\n",
    "    os.makedirs(directory_model)\n",
    "\n",
    "if not os.path.exists(directory_graph):\n",
    "    os.makedirs(directory_graph)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the maximum number of episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPISODES = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps to follow to train the model\n",
    "\n",
    "Set the values of the hyperparameter and initialize the neural network model through the command\n",
    "```python\n",
    "agent = DQNAgent(state_size, action_size)\n",
    "```\n",
    "\n",
    "### Hyperparameters\n",
    "\n",
    "- discount_factor: discount factor gamma\n",
    "- learning_rate: learning rate of the model\n",
    "- epsilon: Initial value of ε for ε-greedy policy\n",
    "- epsilon_decay: Decay rate of ε\n",
    "- epsilon_min: Minimum value of ε. Cannot decay beyound this value\n",
    "- batch_size: Batch size to train the network\n",
    "- train_start: Minimum samples required in memory to start training the network\n",
    "- memory : deque(maxlen=1000) : Size of the memory to store samples \n",
    "\n",
    " \n",
    "\n",
    "### Training the model\n",
    "\n",
    "We know the update policy for Q-learning as:\n",
    "$Q_{t} (S_{t}, a) = Q_{t}  (S_{t}, a) + \\alpha (R_{t+1} + \\gamma *  \\max\\limits_a  Q_{t}(S_{t+1}, a) - Q_{t} (S_{t}, a)]$\n",
    "\n",
    "\n",
    "$Target : reward + (discount  \\: Factor) * (max(next \\: Q \\: value))$\n",
    " \n",
    "\n",
    "Finally, we will train the model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        \n",
    "        # If you want to see Cartpole learning, then change to True\n",
    "        self.render = True\n",
    "        self.load_model = False\n",
    "\n",
    "        # Define size of state and action\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "        # These are hyper parameters for the DQN\n",
    "        self.discount_factor = 0.91\n",
    "        self.learning_rate = 0.001\n",
    "        \n",
    "        \n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_decay = 0.9999\n",
    "        self.epsilon_min = 0.01\n",
    "        \n",
    "        self.batch_size = 32\n",
    "        self.train_start = 500\n",
    "        \n",
    "        # create replay memory using deque\n",
    "        self.memory = deque(maxlen=3000)\n",
    "\n",
    "        # create main model and target model\n",
    "        self.model = self.build_model()\n",
    "        self.target_model = self.build_model()\n",
    "\n",
    "        # initialize target model\n",
    "        self.update_target_model()\n",
    "        \n",
    "        #self.save_model_graph()\n",
    "\n",
    "        #if self.load_model:\n",
    "#         self.model.load_weights(\"./save_model/cartpole_dqn.h5\")\n",
    "#         self.epsilon = 0.0\n",
    "\n",
    "    # approximate Q function using Neural Network\n",
    "    # state is input and Q Value of each action is output of network\n",
    "    def build_model(self):\n",
    "        '''\n",
    "        TODO:\n",
    "        Build multilayer perceptron to train the Q(s,a) function. In this neural network, the input will be states and the output \n",
    "        will be Q(s,a) for each (state,action). \n",
    "        Note: Since the ouput Q(s,a) is not restricted from 0 to 1, we use 'linear activation' as output layer.\n",
    "\n",
    "        Loss Function:\n",
    "        Loss=1/2 * (R_t + γ∗max Q_t (S_{t+1},a)−Q_t(S_t,a)^2\n",
    "               which is 'mean squared error'\n",
    "\n",
    "        '''\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Dense(32, input_dim=self.state_size, activation='relu',\n",
    "                        kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(32, activation='relu',\n",
    "                        kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(self.action_size, activation='linear',\n",
    "                        kernel_initializer='he_uniform'))\n",
    "        model.summary()\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "    \n",
    "    def save_model_graph(self):\n",
    "        # serialize model to JSON\n",
    "        model_json = self.model.to_json()\n",
    "        with open(\"./save_model/cartpole_dqn_model.json\", \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "\n",
    "    # after some time interval update the target model to be same with model\n",
    "    def update_target_model(self):\n",
    "        '''\n",
    "        TODO:\n",
    "        Update the target Q-value network to current Q-value network after training for a episode. This means that weights an\n",
    "        biases of target Q-value network will become same as current Q-value network.\n",
    "        '''\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "    # get action from model using epsilon-greedy policy\n",
    "    def get_action(self, state):\n",
    "        '''\n",
    "        Select action\n",
    "        Args:\n",
    "            state: At any given state, choose action\n",
    "        \n",
    "        TODO:\n",
    "        Choose action according to ε-greedy policy. We generate a random number over [0, 1) from uniform distribution.\n",
    "        If the generated number is less than ε, we will explore, otherwise we will exploit the policy by choosing the\n",
    "        action which has maximum Q-value.\n",
    "        \n",
    "        More the ε value, more will be exploration and less exploitation.\n",
    "        \n",
    "        '''\n",
    "        # choose random action if generated random number is less than ε.\n",
    "        # Action is represented by index, 0-Number of actions, like (0,1,2,3) for 4 actions\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        # if generated random number is greater than ε, choose the action which has max Q-value\n",
    "        else:\n",
    "            q_value = self.model.predict(state)\n",
    "            return np.argmax(q_value[0])\n",
    "\n",
    "    # save sample <s,a,r,s'> to the replay memory\n",
    "    def append_sample(self, state, action, reward, next_state, done):\n",
    "        '''\n",
    "        Save sample in memory and decay ε after we generate each sample from environment. \n",
    "        \n",
    "        Args:\n",
    "            (state, action, reward, next_state, done)- <s,a,r,s',done> \n",
    "        \n",
    "        TODO:\n",
    "            We are saving each sample  (state, action, reward, next_state, done) of the episode, in a memory. Memory can be \n",
    "            defined by queue. We will dequeue sample of batch size from the memory and use it to train the neural network.\n",
    "            \n",
    "            ε-decay:\n",
    "            With ε, we explore and with 1-ε, we exploit. Initially we want to explore more, but at later point, after training \n",
    "            the model, we have good policy to choose better action. So, at that point, we want to expoit more and explore less.\n",
    "            So, we want to decrease the value of ε, by which we explore. \n",
    "            \n",
    "            self.epsilon_min:\n",
    "            Minimum value of ε, by which we want to explore. If the current value of ε is greater then \n",
    "            minimum value to ε, we will decay ε gradually, when generating samples. \n",
    "            \n",
    "            Note: The rate by which we will decrease ε should be slow, otherwise we will not explore much and instead settle\n",
    "            for suboptimal policy instead of optiomal policy. \n",
    "    \n",
    "        '''\n",
    "        # Adding sample to the memory. \n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        \n",
    "        # Decay in ε after we generate each sample from the environment\n",
    "        self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    # pick samples randomly from replay memory (with batch_size) and train the network\n",
    "    def train_model(self):\n",
    "        '''\n",
    "        Train the neural network to find the best policy\n",
    "        \n",
    "        TODO:\n",
    "        1. Sample <s,a,r,s',done> of batch size from the memory\n",
    "        2. Set the target as R_t + γ∗max Q_t(S_{t+1},a)−Q_t(S_t,a)\n",
    "        3. Set the target only for the action we took in the environment. For the other actions, we don't wan't to \n",
    "        update the network. \n",
    "        4. Remember that we already the actions that we took when generating sample from environment\n",
    "        4. To find the Q_t(S_{t+1},a), we input the next state s' to the model, and we get Q-value for all the actions\n",
    "        5. To find the Q_t(S_t,a), we input the current state s to the model, and we get Q-value for all the actions\n",
    "        6. Train the model\n",
    "        \n",
    "        Note:\n",
    "        We use 2 different neural network for Q_t(S_t,a) and target Q_t(S_{t+1},a). This is so because we are \n",
    "        constantly updating the current Q-value network at each and every timestep in a episode. Therefore, the target \n",
    "        Q-value will change subsequently. The network can become destabilized by falling into feedback loops between the\n",
    "        target and current Q-values.\n",
    "        We update the target Q-value network only after completion of a batch. We update the target Q-value with the \n",
    "        current Q-value network. \n",
    "        \n",
    "        '''\n",
    "        # We start the training only when we have sufficient sample in the memory. We set the number of samples required\n",
    "        # start training in variable train_start\n",
    "        if len(self.memory) < self.train_start:\n",
    "            return\n",
    "        \n",
    "        # Sample batch from the memory\n",
    "        batch_size = min(self.batch_size, len(self.memory))\n",
    "        mini_batch = random.sample(self.memory, batch_size)\n",
    "     \n",
    "        # Initialise the variables update_input and update_target for a batch for storing the s and s'.\n",
    "        # Later, we will use it to store Q_t(S_t,a_t) and Q_t(S_{t+1},a)\n",
    "        update_input = np.zeros((batch_size, self.state_size))\n",
    "        update_target = np.zeros((batch_size, self.state_size))\n",
    "        action, reward, done = [], [], []\n",
    "\n",
    "        # Set the values of input, action, reward, target and done using memory\n",
    "        # Note the order of <s,a,r,s',done> \n",
    "        for i in range(self.batch_size):\n",
    "            update_input[i] = mini_batch[i][0]\n",
    "            action.append(mini_batch[i][1])\n",
    "            reward.append(mini_batch[i][2])\n",
    "            update_target[i] = mini_batch[i][3]\n",
    "            done.append(mini_batch[i][4])\n",
    "\n",
    "        # Set the target as Q values predicted from the current state and next state \n",
    "        # store Q_t(S_t,a_t) and Q_t(S_{t+1},a) in target and target_val\n",
    "        target = self.model.predict(update_input)\n",
    "        target_val = self.target_model.predict(update_target)\n",
    "        \n",
    "        \n",
    "        # Update the target value according to the update policy of Q-learning\n",
    "        # R_t + γ ∗ max Q_t(S_{t+1},a)−Q_t(S_t,a_t)\n",
    "        for i in range(self.batch_size):\n",
    "            # Q Learning: get maximum Q value at s' from target model\n",
    "            if done[i]:\n",
    "                target[i][action[i]] = reward[i]\n",
    "            else:\n",
    "                target[i][action[i]] = reward[i] + self.discount_factor * (\n",
    "                    np.amax(target_val[i]))\n",
    "\n",
    "        # and do the model fit!\n",
    "        self.model.fit(update_input, target, batch_size=self.batch_size,\n",
    "                       epochs=1, verbose=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main function\n",
    "Here, we will generate samples <s, a, r, s'> in episodes using the environment. Save these samples in memory and train the model.\n",
    "If the mean of scores of last 30 episode is bigger than 490 stop training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                288       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 1,476\n",
      "Trainable params: 1,476\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 32)                288       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 1,476\n",
      "Trainable params: 1,476\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "episode: 0   score: -174.3253   time_steps: 96  landing_ops_time: 0   landing_coord: (0.3111, -0.0976)  epsilon: 0.9905\n",
      "episode: 1   score: -303.0917   time_steps: 90  landing_ops_time: 0   landing_coord: (0.4048, 0.0388)  epsilon: 0.9818\n",
      "episode: 2   score: -118.1575   time_steps: 82  landing_ops_time: 0   landing_coord: (-0.197, -0.0424)  epsilon: 0.9738\n",
      "episode: 3   score: -148.3836   time_steps: 64  landing_ops_time: 0   landing_coord: (0.5109, -0.0101)  epsilon: 0.9677\n",
      "episode: 4   score: -130.5358   time_steps: 58  landing_ops_time: 0   landing_coord: (0.2186, -0.0079)  epsilon: 0.9622\n",
      "episode: 5   score: -213.3339   time_steps: 104  landing_ops_time: 0   landing_coord: (-0.7359, -0.0195)  epsilon: 0.9524\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "episode: 6   score: -183.521   time_steps: 76  landing_ops_time: 0   landing_coord: (0.7013, 0.2709)  epsilon: 0.9453\n",
      "episode: 7   score: -307.3048   time_steps: 96  landing_ops_time: 0   landing_coord: (0.9201, 0.021)  epsilon: 0.9363\n",
      "episode: 8   score: -109.9969   time_steps: 72  landing_ops_time: 0   landing_coord: (0.2691, 0.0237)  epsilon: 0.9297\n",
      "episode: 9   score: -63.0062   time_steps: 94  landing_ops_time: 0   landing_coord: (0.0577, -0.0428)  epsilon: 0.9211\n",
      "episode: 10   score: -102.9334   time_steps: 82  landing_ops_time: 0   landing_coord: (-0.2257, -0.0499)  epsilon: 0.9137\n",
      "episode: 11   score: -143.9325   time_steps: 83  landing_ops_time: 0   landing_coord: (0.3049, -0.0652)  epsilon: 0.9062\n",
      "episode: 12   score: -91.5824   time_steps: 81  landing_ops_time: 0   landing_coord: (0.1523, -0.0428)  epsilon: 0.899\n",
      "episode: 13   score: -311.6459   time_steps: 105  landing_ops_time: 0   landing_coord: (1.0128, 0.004)  epsilon: 0.8897\n",
      "episode: 14   score: -101.6295   time_steps: 60  landing_ops_time: 0   landing_coord: (0.425, -0.1005)  epsilon: 0.8844\n",
      "episode: 15   score: -148.5832   time_steps: 64  landing_ops_time: 0   landing_coord: (-0.4647, -0.0118)  epsilon: 0.8789\n",
      "episode: 16   score: -77.5091   time_steps: 126  landing_ops_time: 0   landing_coord: (-0.4341, -0.1054)  epsilon: 0.868\n",
      "episode: 17   score: -86.4923   time_steps: 103  landing_ops_time: 0   landing_coord: (0.2605, -0.0422)  epsilon: 0.8592\n",
      "episode: 18   score: -68.5641   time_steps: 58  landing_ops_time: 0   landing_coord: (0.2456, -0.0524)  epsilon: 0.8543\n",
      "episode: 19   score: -94.7998   time_steps: 56  landing_ops_time: 0   landing_coord: (-0.3615, -0.004)  epsilon: 0.8496\n",
      "episode: 20   score: -122.8774   time_steps: 59  landing_ops_time: 0   landing_coord: (0.2527, -0.0754)  epsilon: 0.8447\n",
      "episode: 21   score: -155.8039   time_steps: 102  landing_ops_time: 0   landing_coord: (0.522, -0.0427)  epsilon: 0.8362\n",
      "episode: 22   score: -132.9208   time_steps: 75  landing_ops_time: 0   landing_coord: (0.551, 0.0251)  epsilon: 0.83\n",
      "episode: 23   score: -173.0098   time_steps: 81  landing_ops_time: 0   landing_coord: (0.6141, -0.0463)  epsilon: 0.8234\n",
      "episode: 24   score: -313.0274   time_steps: 96  landing_ops_time: 0   landing_coord: (-0.3875, -0.0113)  epsilon: 0.8156\n",
      "episode: 25   score: -187.7345   time_steps: 99  landing_ops_time: 0   landing_coord: (0.4053, 0.0002)  epsilon: 0.8077\n",
      "episode: 26   score: -116.1335   time_steps: 77  landing_ops_time: 0   landing_coord: (0.1695, -0.0371)  epsilon: 0.8015\n",
      "episode: 27   score: -72.0108   time_steps: 70  landing_ops_time: 0   landing_coord: (0.0988, -0.0428)  epsilon: 0.796\n",
      "episode: 28   score: -94.4513   time_steps: 100  landing_ops_time: 0   landing_coord: (0.4308, 0.0344)  epsilon: 0.7882\n",
      "episode: 29   score: -104.8711   time_steps: 125  landing_ops_time: 0   landing_coord: (0.1676, -0.0079)  epsilon: 0.7785\n",
      "episode: 30   score: -84.5667   time_steps: 80  landing_ops_time: 0   landing_coord: (-0.2693, -0.0687)  epsilon: 0.7724\n",
      "episode: 31   score: -107.9078   time_steps: 77  landing_ops_time: 0   landing_coord: (0.5398, -0.1941)  epsilon: 0.7665\n",
      "episode: 32   score: -78.3877   time_steps: 65  landing_ops_time: 0   landing_coord: (-0.3063, 0.0543)  epsilon: 0.7616\n",
      "episode: 33   score: -172.8938   time_steps: 78  landing_ops_time: 0   landing_coord: (-0.6027, -0.1192)  epsilon: 0.7558\n",
      "episode: 34   score: -141.4313   time_steps: 71  landing_ops_time: 0   landing_coord: (-0.4085, -0.0177)  epsilon: 0.7505\n",
      "episode: 35   score: -286.5653   time_steps: 143  landing_ops_time: 0   landing_coord: (-0.497, 0.1861)  epsilon: 0.7399\n",
      "episode: 36   score: -97.5213   time_steps: 66  landing_ops_time: 0   landing_coord: (-0.4156, -0.1982)  epsilon: 0.7351\n",
      "episode: 37   score: -120.9624   time_steps: 60  landing_ops_time: 0   landing_coord: (0.2965, -0.0444)  epsilon: 0.7308\n",
      "episode: 38   score: -87.655   time_steps: 127  landing_ops_time: 0   landing_coord: (-0.8014, 0.0134)  epsilon: 0.7216\n",
      "episode: 39   score: -76.9774   time_steps: 63  landing_ops_time: 0   landing_coord: (-0.2212, -0.0305)  epsilon: 0.7172\n",
      "episode: 40   score: -168.1693   time_steps: 86  landing_ops_time: 0   landing_coord: (-0.6971, -0.0311)  epsilon: 0.7111\n",
      "episode: 41   score: -81.2171   time_steps: 132  landing_ops_time: 0   landing_coord: (-0.6798, -0.0525)  epsilon: 0.7019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 42   score: -57.7239   time_steps: 65  landing_ops_time: 0   landing_coord: (0.0595, -0.0428)  epsilon: 0.6974\n",
      "episode: 43   score: -148.9137   time_steps: 101  landing_ops_time: 0   landing_coord: (0.5724, 0.0686)  epsilon: 0.6904\n",
      "episode: 44   score: -89.7979   time_steps: 58  landing_ops_time: 0   landing_coord: (-0.4012, 0.0768)  epsilon: 0.6865\n",
      "episode: 45   score: -0.3326   time_steps: 82  landing_ops_time: 0   landing_coord: (-0.026, -0.0428)  epsilon: 0.681\n",
      "episode: 46   score: -109.9019   time_steps: 113  landing_ops_time: 0   landing_coord: (0.6142, 0.0548)  epsilon: 0.6734\n",
      "episode: 47   score: -68.6323   time_steps: 73  landing_ops_time: 0   landing_coord: (-0.3401, 0.0434)  epsilon: 0.6686\n",
      "episode: 48   score: -35.5505   time_steps: 71  landing_ops_time: 0   landing_coord: (-0.2093, -0.0303)  epsilon: 0.6639\n",
      "episode: 49   score: -139.76   time_steps: 75  landing_ops_time: 0   landing_coord: (0.3739, -0.0192)  epsilon: 0.659\n",
      "episode: 50   score: -118.3558   time_steps: 105  landing_ops_time: 0   landing_coord: (0.7078, -0.1222)  epsilon: 0.6522\n",
      "episode: 51   score: -149.2406   time_steps: 124  landing_ops_time: 67.5   landing_coord: (0.354, -0.0147)  epsilon: 0.6442\n",
      "episode: 52   score: -273.313   time_steps: 173  landing_ops_time: 66.7   landing_coord: (0.2043, -0.0228)  epsilon: 0.6332\n",
      "episode: 53   score: -127.829   time_steps: 61  landing_ops_time: 77.5   landing_coord: (0.4398, -0.1019)  epsilon: 0.6294\n",
      "episode: 54   score: -96.7173   time_steps: 56  landing_ops_time: 73.5   landing_coord: (0.3654, 0.1167)  epsilon: 0.626\n",
      "episode: 55   score: -84.2609   time_steps: 69  landing_ops_time: 73.3   landing_coord: (-0.2919, -0.0536)  epsilon: 0.6217\n",
      "episode: 56   score: -188.7302   time_steps: 152  landing_ops_time: 72.0   landing_coord: (0.3891, -0.0012)  epsilon: 0.6124\n",
      "episode: 57   score: -113.8371   time_steps: 95  landing_ops_time: 75.9   landing_coord: (0.5128, -0.0479)  epsilon: 0.6067\n",
      "episode: 58   score: -128.2907   time_steps: 96  landing_ops_time: 78.1   landing_coord: (-0.6278, -0.0429)  epsilon: 0.601\n",
      "episode: 59   score: -65.7619   time_steps: 53  landing_ops_time: 80.6   landing_coord: (0.3755, 0.125)  epsilon: 0.5978\n",
      "episode: 60   score: -100.4452   time_steps: 109  landing_ops_time: 78.4   landing_coord: (-0.0071, -0.0336)  epsilon: 0.5914\n",
      "episode: 61   score: -101.6931   time_steps: 93  landing_ops_time: 78.8   landing_coord: (-0.5275, 0.0862)  epsilon: 0.586\n",
      "episode: 62   score: -164.0595   time_steps: 166  landing_ops_time: 75.7   landing_coord: (0.1756, -0.0348)  epsilon: 0.5764\n",
      "episode: 63   score: -122.5976   time_steps: 62  landing_ops_time: 75.0   landing_coord: (-0.3554, -0.1253)  epsilon: 0.5729\n",
      "episode: 64   score: -96.6269   time_steps: 98  landing_ops_time: 75.1   landing_coord: (-0.108, -0.0389)  epsilon: 0.5674\n",
      "episode: 65   score: -59.844   time_steps: 77  landing_ops_time: 79.3   landing_coord: (-0.208, -0.0292)  epsilon: 0.5631\n",
      "episode: 66   score: -105.4254   time_steps: 102  landing_ops_time: 80.1   landing_coord: (-0.7427, 0.1615)  epsilon: 0.5574\n",
      "episode: 67   score: -199.7472   time_steps: 86  landing_ops_time: 75.1   landing_coord: (-0.5443, -0.0504)  epsilon: 0.5527\n",
      "episode: 68   score: -131.6512   time_steps: 81  landing_ops_time: 74.2   landing_coord: (0.5784, -0.0869)  epsilon: 0.5483\n",
      "episode: 69   score: -144.2209   time_steps: 127  landing_ops_time: 72.7   landing_coord: (0.6621, -0.1501)  epsilon: 0.5414\n",
      "episode: 70   score: -99.0036   time_steps: 86  landing_ops_time: 80.1   landing_coord: (-0.6744, -0.1658)  epsilon: 0.5369\n",
      "episode: 71   score: -102.5182   time_steps: 87  landing_ops_time: 77.8   landing_coord: (-0.4655, 0.0355)  epsilon: 0.5323\n",
      "episode: 72   score: -117.6693   time_steps: 65  landing_ops_time: 77.2   landing_coord: (0.4201, -0.1922)  epsilon: 0.5289\n",
      "episode: 73   score: -183.7491   time_steps: 117  landing_ops_time: 67.1   landing_coord: (0.1401, -0.0187)  epsilon: 0.5228\n",
      "episode: 74   score: -183.9074   time_steps: 122  landing_ops_time: 72.6   landing_coord: (1.0016, -0.1478)  epsilon: 0.5165\n",
      "episode: 75   score: -406.6188   time_steps: 157  landing_ops_time: 75.0   landing_coord: (0.8741, -0.3355)  epsilon: 0.5085\n",
      "episode: 76   score: -84.0828   time_steps: 53  landing_ops_time: 83.0   landing_coord: (-0.3714, 0.1338)  epsilon: 0.5058\n",
      "episode: 77   score: -10.3339   time_steps: 62  landing_ops_time: 78.1   landing_coord: (-0.0258, -0.0428)  epsilon: 0.5028\n",
      "episode: 78   score: -165.9568   time_steps: 108  landing_ops_time: 75.7   landing_coord: (-0.5897, 0.0815)  epsilon: 0.4974\n",
      "episode: 79   score: -141.5906   time_steps: 141  landing_ops_time: 78.4   landing_coord: (0.7308, -0.3296)  epsilon: 0.4905\n",
      "episode: 80   score: -287.055   time_steps: 126  landing_ops_time: 79.8   landing_coord: (-0.3134, -0.0468)  epsilon: 0.4844\n",
      "episode: 81   score: -64.1797   time_steps: 76  landing_ops_time: 83.8   landing_coord: (-0.3673, 0.0118)  epsilon: 0.4808\n",
      "episode: 82   score: -119.5052   time_steps: 109  landing_ops_time: 82.7   landing_coord: (-0.4688, -0.1238)  epsilon: 0.4756\n",
      "episode: 83   score: -171.8294   time_steps: 172  landing_ops_time: 87.1   landing_coord: (0.7651, -0.0146)  epsilon: 0.4676\n",
      "episode: 84   score: -71.4699   time_steps: 84  landing_ops_time: 92.6   landing_coord: (-0.4858, 0.0249)  epsilon: 0.4637\n",
      "episode: 85   score: -81.2856   time_steps: 78  landing_ops_time: 88.8   landing_coord: (-0.5322, -0.0066)  epsilon: 0.4601\n",
      "episode: 86   score: -77.8419   time_steps: 81  landing_ops_time: 80.9   landing_coord: (0.5445, -0.0177)  epsilon: 0.4565\n",
      "episode: 87   score: -78.7597   time_steps: 111  landing_ops_time: 83.7   landing_coord: (0.2116, -0.0194)  epsilon: 0.4515\n",
      "episode: 88   score: -97.9448   time_steps: 69  landing_ops_time: 88.6   landing_coord: (0.3857, -0.1688)  epsilon: 0.4484\n",
      "episode: 89   score: -76.873   time_steps: 86  landing_ops_time: 84.7   landing_coord: (-0.4436, -0.1818)  epsilon: 0.4446\n",
      "episode: 90   score: -152.27   time_steps: 159  landing_ops_time: 79.2   landing_coord: (-0.1358, -0.0345)  epsilon: 0.4376\n",
      "episode: 91   score: -63.6627   time_steps: 107  landing_ops_time: 82.5   landing_coord: (-0.1689, -0.0418)  epsilon: 0.433\n",
      "episode: 92   score: -40.7589   time_steps: 82  landing_ops_time: 85.6   landing_coord: (0.3503, -0.0009)  epsilon: 0.4295\n",
      "episode: 93   score: -4.007   time_steps: 89  landing_ops_time: 82.9   landing_coord: (0.0742, -0.0428)  epsilon: 0.4258\n",
      "episode: 94   score: -52.246   time_steps: 59  landing_ops_time: 74.6   landing_coord: (0.2517, -0.0524)  epsilon: 0.4233\n",
      "episode: 95   score: -52.027   time_steps: 83  landing_ops_time: 72.1   landing_coord: (-0.6873, 0.0737)  epsilon: 0.4199\n",
      "episode: 96   score: -40.8283   time_steps: 82  landing_ops_time: 72.6   landing_coord: (-0.3709, -0.0075)  epsilon: 0.4165\n",
      "episode: 97   score: -100.5414   time_steps: 87  landing_ops_time: 72.7   landing_coord: (0.3327, -0.0146)  epsilon: 0.4129\n",
      "episode: 98   score: -668.9589   time_steps: 249  landing_ops_time: 70.3   landing_coord: (1.0036, 0.7598)  epsilon: 0.4028\n",
      "episode: 99   score: -217.0844   time_steps: 114  landing_ops_time: 88.3   landing_coord: (-0.7907, -0.035)  epsilon: 0.3983\n",
      "episode: 100   score: -558.7282   time_steps: 243  landing_ops_time: 91.1   landing_coord: (-0.7631, -0.2333)  epsilon: 0.3887\n",
      "episode: 101   score: 6.3489   time_steps: 99  landing_ops_time: 99.5   landing_coord: (0.5167, -0.0323)  epsilon: 0.3849\n",
      "episode: 102   score: -490.2184   time_steps: 182  landing_ops_time: 98.7   landing_coord: (-0.8367, -0.0327)  epsilon: 0.378\n",
      "episode: 103   score: -91.8696   time_steps: 57  landing_ops_time: 108.7   landing_coord: (0.464, -0.0255)  epsilon: 0.3759\n",
      "episode: 104   score: -1120.3276   time_steps: 381  landing_ops_time: 105.5   landing_coord: (-0.2717, -0.0196)  epsilon: 0.3619\n",
      "episode: 105   score: -94.2859   time_steps: 119  landing_ops_time: 137.7   landing_coord: (-0.9927, -0.0816)  epsilon: 0.3577\n",
      "episode: 106   score: -19.2908   time_steps: 82  landing_ops_time: 141.3   landing_coord: (-0.075, -0.0428)  epsilon: 0.3548\n",
      "episode: 107   score: -41.1649   time_steps: 101  landing_ops_time: 141.3   landing_coord: (-0.6526, 0.2245)  epsilon: 0.3513\n",
      "episode: 108   score: -36.3974   time_steps: 96  landing_ops_time: 142.7   landing_coord: (0.2595, -0.056)  epsilon: 0.3479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 109   score: -330.6591   time_steps: 158  landing_ops_time: 127.4   landing_coord: (-0.6381, 0.1699)  epsilon: 0.3425\n",
      "episode: 110   score: -38.1344   time_steps: 75  landing_ops_time: 131.8   landing_coord: (0.4917, 0.1146)  epsilon: 0.34\n",
      "episode: 111   score: -5.6415   time_steps: 85  landing_ops_time: 115.0   landing_coord: (0.2852, -0.0097)  epsilon: 0.3371\n",
      "episode: 112   score: -449.2371   time_steps: 292  landing_ops_time: 113.6   landing_coord: (0.3425, -0.0689)  epsilon: 0.3275\n",
      "episode: 113   score: -1042.2438   time_steps: 411  landing_ops_time: 124.6   landing_coord: (0.1168, -0.0359)  epsilon: 0.3143\n",
      "episode: 114   score: -73.0946   time_steps: 71  landing_ops_time: 160.0   landing_coord: (0.4329, -0.1832)  epsilon: 0.3121\n",
      "episode: 115   score: -36.7464   time_steps: 101  landing_ops_time: 129.0   landing_coord: (-0.2732, 0.0296)  epsilon: 0.309\n",
      "episode: 116   score: -84.2464   time_steps: 64  landing_ops_time: 127.2   landing_coord: (-0.4263, -0.0482)  epsilon: 0.3071\n",
      "episode: 117   score: -166.2931   time_steps: 96  landing_ops_time: 125.4   landing_coord: (0.2833, -0.0412)  epsilon: 0.3042\n",
      "episode: 118   score: -64.9094   time_steps: 165  landing_ops_time: 124.9   landing_coord: (0.1014, -0.0415)  epsilon: 0.2992\n",
      "episode: 119   score: -81.5429   time_steps: 111  landing_ops_time: 131.8   landing_coord: (0.1723, -0.0058)  epsilon: 0.296\n",
      "episode: 120   score: -70.5727   time_steps: 113  landing_ops_time: 127.1   landing_coord: (0.0073, -0.0195)  epsilon: 0.2927\n",
      "episode: 121   score: 2.3344   time_steps: 69  landing_ops_time: 130.9   landing_coord: (-0.0627, -0.0428)  epsilon: 0.2907\n",
      "episode: 122   score: -241.0692   time_steps: 205  landing_ops_time: 129.3   landing_coord: (-0.6259, -0.0104)  epsilon: 0.2848\n",
      "episode: 123   score: -76.6661   time_steps: 88  landing_ops_time: 120.6   landing_coord: (-0.7062, -0.2833)  epsilon: 0.2823\n",
      "episode: 124   score: -272.8418   time_steps: 196  landing_ops_time: 88.3   landing_coord: (-0.405, 0.1044)  epsilon: 0.2769\n",
      "episode: 125   score: -224.4502   time_steps: 178  landing_ops_time: 100.8   landing_coord: (-0.2099, -0.021)  epsilon: 0.272\n",
      "episode: 126   score: -78.9205   time_steps: 117  landing_ops_time: 108.5   landing_coord: (0.2068, -0.0204)  epsilon: 0.2689\n",
      "episode: 127   score: -50.7304   time_steps: 74  landing_ops_time: 113.8   landing_coord: (0.5577, 0.0462)  epsilon: 0.2669\n",
      "episode: 128   score: -761.7148   time_steps: 353  landing_ops_time: 111.6   landing_coord: (0.6422, -0.0928)  epsilon: 0.2577\n",
      "episode: 129   score: -164.8081   time_steps: 150  landing_ops_time: 130.4   landing_coord: (1.0008, -0.0384)  epsilon: 0.2539\n",
      "episode: 130   score: -133.1399   time_steps: 107  landing_ops_time: 134.3   landing_coord: (0.7394, -0.3684)  epsilon: 0.2512\n",
      "episode: 131   score: -542.6138   time_steps: 335  landing_ops_time: 133.7   landing_coord: (-0.5246, 0.1635)  epsilon: 0.243\n",
      "episode: 132   score: -1241.6127   time_steps: 430  landing_ops_time: 160.3   landing_coord: (-0.7016, -0.0488)  epsilon: 0.2328\n",
      "episode: 133   score: -39.5065   time_steps: 71  landing_ops_time: 182.8   landing_coord: (0.4001, -0.0824)  epsilon: 0.2311\n",
      "episode: 134   score: -40.9312   time_steps: 157  landing_ops_time: 181.1   landing_coord: (-0.4503, -0.0943)  epsilon: 0.2276\n",
      "episode: 135   score: -24.5773   time_steps: 194  landing_ops_time: 177.2   landing_coord: (-0.0428, -0.0388)  epsilon: 0.2232\n",
      "episode: 136   score: -184.6198   time_steps: 249  landing_ops_time: 178.8   landing_coord: (-0.2162, -0.0397)  epsilon: 0.2177\n",
      "episode: 137   score: -46.1895   time_steps: 67  landing_ops_time: 192.0   landing_coord: (-0.2819, 0.0095)  epsilon: 0.2163\n",
      "episode: 138   score: -57.591   time_steps: 60  landing_ops_time: 191.3   landing_coord: (0.3087, 0.0654)  epsilon: 0.215\n",
      "episode: 139   score: -201.589   time_steps: 256  landing_ops_time: 162.0   landing_coord: (-0.134, -0.0428)  epsilon: 0.2096\n",
      "episode: 140   score: -1227.1694   time_steps: 433  landing_ops_time: 172.6   landing_coord: (-0.3812, -0.1258)  epsilon: 0.2008\n",
      "episode: 141   score: -69.2691   time_steps: 60  landing_ops_time: 205.2   landing_coord: (0.4946, 0.0602)  epsilon: 0.1996\n",
      "episode: 142   score: -100.5206   time_steps: 103  landing_ops_time: 177.7   landing_coord: (0.7451, 0.0109)  epsilon: 0.1975\n",
      "episode: 143   score: -1994.2207   time_steps: 547  landing_ops_time: 145.0   landing_coord: (-0.162, -0.0372)  epsilon: 0.187\n",
      "episode: 144   score: -2925.568   time_steps: 719  landing_ops_time: 192.6   landing_coord: (-0.1399, -0.0427)  epsilon: 0.1741\n",
      "episode: 145   score: 12.7493   time_steps: 70  landing_ops_time: 248.8   landing_coord: (0.186, -0.0156)  epsilon: 0.1729\n",
      "episode: 146   score: -66.783   time_steps: 59  landing_ops_time: 236.4   landing_coord: (0.4332, 0.0291)  epsilon: 0.1719\n",
      "episode: 147   score: -3204.0057   time_steps: 760  landing_ops_time: 217.4   landing_coord: (-0.1709, -0.0391)  epsilon: 0.1593\n",
      "episode: 148   score: -865.0785   time_steps: 393  landing_ops_time: 286.7   landing_coord: (0.4675, -0.1205)  epsilon: 0.1532\n",
      "episode: 149   score: -86.5912   time_steps: 204  landing_ops_time: 320.0   landing_coord: (-0.5812, 0.121)  epsilon: 0.1501\n",
      "episode: 150   score: -44.6038   time_steps: 205  landing_ops_time: 314.8   landing_coord: (-0.7426, -0.1519)  epsilon: 0.1471\n",
      "episode: 151   score: -4528.691   time_steps: 1001  landing_ops_time: 292.0   landing_coord: (-0.0811, 0.0238)  epsilon: 0.1331\n",
      "episode: 152   score: -4454.5865   time_steps: 1001  landing_ops_time: 386.1   landing_coord: (0.0404, 0.0039)  epsilon: 0.1204\n",
      "episode: 153   score: -3.0777   time_steps: 255  landing_ops_time: 475.9   landing_coord: (-0.2232, -0.049)  epsilon: 0.1174\n",
      "episode: 154   score: -74.2153   time_steps: 78  landing_ops_time: 446.7   landing_coord: (-0.5299, -0.0016)  epsilon: 0.1165\n",
      "episode: 155   score: -67.4528   time_steps: 86  landing_ops_time: 382.6   landing_coord: (-0.5319, 0.1099)  epsilon: 0.1155\n",
      "episode: 156   score: -260.776   time_steps: 381  landing_ops_time: 384.2   landing_coord: (0.4317, 0.0348)  epsilon: 0.1112\n",
      "episode: 157   score: -72.7765   time_steps: 54  landing_ops_time: 416.4   landing_coord: (-0.4082, 0.0577)  epsilon: 0.1106\n",
      "episode: 158   score: -60.6237   time_steps: 73  landing_ops_time: 345.8   landing_coord: (-0.3196, 0.0209)  epsilon: 0.1098\n",
      "episode: 159   score: -9.2309   time_steps: 146  landing_ops_time: 313.8   landing_coord: (0.2857, 0.0014)  epsilon: 0.1083\n",
      "episode: 160   score: -189.6378   time_steps: 302  landing_ops_time: 308.0   landing_coord: (1.0033, 0.3383)  epsilon: 0.105\n",
      "episode: 161   score: -73.5588   time_steps: 79  landing_ops_time: 317.7   landing_coord: (-0.5101, 0.0993)  epsilon: 0.1042\n",
      "episode: 162   score: -105.8814   time_steps: 118  landing_ops_time: 225.5   landing_coord: (0.6405, -0.1311)  epsilon: 0.103\n",
      "episode: 163   score: -16.3456   time_steps: 72  landing_ops_time: 137.2   landing_coord: (-0.2258, -0.0495)  epsilon: 0.1023\n",
      "episode: 164   score: -50.6344   time_steps: 61  landing_ops_time: 118.9   landing_coord: (-0.477, -0.1262)  epsilon: 0.1017\n",
      "episode: 165   score: -32.7873   time_steps: 64  landing_ops_time: 117.2   landing_coord: (0.3127, 0.052)  epsilon: 0.101\n",
      "episode: 166   score: -902.8804   time_steps: 449  landing_ops_time: 115.0   landing_coord: (0.4855, -0.0924)  epsilon: 0.0966\n",
      "episode: 167   score: 8.3538   time_steps: 75  landing_ops_time: 121.8   landing_coord: (-0.1823, -0.0395)  epsilon: 0.0959\n",
      "episode: 168   score: -897.3561   time_steps: 399  landing_ops_time: 123.9   landing_coord: (0.0222, -0.0315)  epsilon: 0.0922\n",
      "episode: 169   score: -4986.0107   time_steps: 1001  landing_ops_time: 156.5   landing_coord: (0.8558, -0.2108)  epsilon: 0.0834\n",
      "episode: 170   score: -1124.4534   time_steps: 416  landing_ops_time: 242.0   landing_coord: (1.0003, -0.4178)  epsilon: 0.08\n",
      "episode: 171   score: -259.3464   time_steps: 101  landing_ops_time: 253.4   landing_coord: (1.001, 0.2447)  epsilon: 0.0792\n",
      "episode: 172   score: -153.7096   time_steps: 77  landing_ops_time: 255.6   landing_coord: (0.6968, -0.0139)  epsilon: 0.0786\n",
      "episode: 173   score: -282.3068   time_steps: 100  landing_ops_time: 251.5   landing_coord: (1.0159, 0.0646)  epsilon: 0.0778\n",
      "episode: 174   score: -116.5448   time_steps: 162  landing_ops_time: 254.3   landing_coord: (-0.7059, -0.3851)  epsilon: 0.0766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 175   score: -52.8396   time_steps: 110  landing_ops_time: 264.4   landing_coord: (0.5832, -0.0094)  epsilon: 0.0757\n",
      "episode: 176   score: -19.2624   time_steps: 95  landing_ops_time: 269.0   landing_coord: (-0.6841, -0.1223)  epsilon: 0.075\n",
      "episode: 177   score: -203.1055   time_steps: 301  landing_ops_time: 233.6   landing_coord: (-0.6874, -0.2177)  epsilon: 0.0728\n",
      "episode: 178   score: -61.0255   time_steps: 145  landing_ops_time: 256.2   landing_coord: (-0.4151, 0.1118)  epsilon: 0.0718\n",
      "episode: 179   score: -12.3179   time_steps: 191  landing_ops_time: 230.8   landing_coord: (-0.1433, -0.033)  epsilon: 0.0704\n",
      "episode: 180   score: -156.7168   time_steps: 236  landing_ops_time: 149.8   landing_coord: (0.6499, 0.068)  epsilon: 0.0688\n",
      "episode: 181   score: -83.3366   time_steps: 155  landing_ops_time: 131.8   landing_coord: (-0.4392, -0.0095)  epsilon: 0.0677\n",
      "episode: 182   score: -2239.8671   time_steps: 583  landing_ops_time: 137.2   landing_coord: (0.3639, 0.0056)  epsilon: 0.0639\n",
      "episode: 183   score: -80.2766   time_steps: 195  landing_ops_time: 187.8   landing_coord: (-0.4376, -0.1675)  epsilon: 0.0627\n",
      "episode: 184   score: -62.7831   time_steps: 77  landing_ops_time: 197.3   landing_coord: (0.5255, 0.179)  epsilon: 0.0622\n",
      "episode: 185   score: -74.6955   time_steps: 226  landing_ops_time: 188.8   landing_coord: (-0.1796, -0.0397)  epsilon: 0.0608\n",
      "episode: 186   score: -41.0103   time_steps: 133  landing_ops_time: 200.4   landing_coord: (0.5296, 0.1455)  epsilon: 0.06\n",
      "episode: 187   score: 17.3994   time_steps: 203  landing_ops_time: 204.2   landing_coord: (0.3681, -0.1203)  epsilon: 0.0588\n",
      "episode: 188   score: -61.5223   time_steps: 81  landing_ops_time: 194.4   landing_coord: (0.5151, -0.0999)  epsilon: 0.0584\n",
      "episode: 189   score: -317.5837   time_steps: 310  landing_ops_time: 188.0   landing_coord: (-0.41, 0.0213)  epsilon: 0.0566\n",
      "episode: 190   score: -81.1436   time_steps: 67  landing_ops_time: 199.9   landing_coord: (0.4942, 0.064)  epsilon: 0.0562\n",
      "episode: 191   score: -1326.875   time_steps: 464  landing_ops_time: 183.0   landing_coord: (-0.2826, -0.0228)  epsilon: 0.0537\n",
      "episode: 192   score: -626.0632   time_steps: 351  landing_ops_time: 213.9   landing_coord: (0.9853, -0.1255)  epsilon: 0.0518\n",
      "episode: 193   score: -293.7578   time_steps: 233  landing_ops_time: 190.7   landing_coord: (0.5275, 0.1291)  epsilon: 0.0506\n",
      "episode: 194   score: -122.2665   time_steps: 261  landing_ops_time: 194.5   landing_coord: (-0.0078, -0.0372)  epsilon: 0.0493\n",
      "episode: 195   score: -1797.8181   time_steps: 574  landing_ops_time: 212.9   landing_coord: (-0.0385, 1e-04)  epsilon: 0.0466\n",
      "episode: 196   score: -539.4492   time_steps: 404  landing_ops_time: 247.7   landing_coord: (0.0248, -0.0006)  epsilon: 0.0447\n",
      "episode: 197   score: -31.0649   time_steps: 330  landing_ops_time: 274.8   landing_coord: (0.0592, -0.0004)  epsilon: 0.0433\n",
      "episode: 198   score: -89.9046   time_steps: 254  landing_ops_time: 287.5   landing_coord: (-1.0009, 0.4449)  epsilon: 0.0422\n",
      "episode: 199   score: -107.3585   time_steps: 354  landing_ops_time: 304.8   landing_coord: (0.031, -0.0011)  epsilon: 0.0408\n",
      "episode: 200   score: -4541.1438   time_steps: 1001  landing_ops_time: 309.2   landing_coord: (-0.9631, 0.2412)  epsilon: 0.0369\n",
      "episode: 201   score: -284.5187   time_steps: 390  landing_ops_time: 402.6   landing_coord: (-0.2365, 0.0428)  epsilon: 0.0355\n",
      "episode: 202   score: -4422.3255   time_steps: 1001  landing_ops_time: 395.2   landing_coord: (-0.309, 0.0174)  epsilon: 0.0321\n",
      "episode: 203   score: -719.059   time_steps: 476  landing_ops_time: 460.2   landing_coord: (-0.1034, -0.0008)  epsilon: 0.0306\n",
      "episode: 204   score: -751.7614   time_steps: 152  landing_ops_time: 484.5   landing_coord: (0.5753, -0.0041)  epsilon: 0.0301\n",
      "episode: 205   score: -4302.3534   time_steps: 1001  landing_ops_time: 473.6   landing_coord: (-0.5719, 0.093)  epsilon: 0.0273\n",
      "episode: 206   score: -2780.3033   time_steps: 804  landing_ops_time: 516.3   landing_coord: (-0.5997, 0.0437)  epsilon: 0.0252\n",
      "episode: 207   score: -30.819   time_steps: 82  landing_ops_time: 556.3   landing_coord: (0.379, -0.1673)  epsilon: 0.025\n",
      "episode: 208   score: -4205.5035   time_steps: 1001  landing_ops_time: 531.5   landing_coord: (-0.3498, -0.0305)  epsilon: 0.0226\n",
      "episode: 209   score: -11.6095   time_steps: 196  landing_ops_time: 606.2   landing_coord: (-0.4337, -0.0495)  epsilon: 0.0222\n",
      "episode: 210   score: -53.0164   time_steps: 269  landing_ops_time: 590.4   landing_coord: (0.1893, -0.0133)  epsilon: 0.0216\n",
      "episode: 211   score: -2284.1157   time_steps: 723  landing_ops_time: 517.2   landing_coord: (-0.3967, -0.0234)  epsilon: 0.0201\n",
      "episode: 212   score: -29.048   time_steps: 211  landing_ops_time: 550.5   landing_coord: (-0.3219, 0.0688)  epsilon: 0.0196\n",
      "episode: 213   score: -4426.5333   time_steps: 1001  landing_ops_time: 471.5   landing_coord: (-0.669, 0.6075)  epsilon: 0.0178\n",
      "episode: 214   score: -264.8429   time_steps: 111  landing_ops_time: 524.0   landing_coord: (0.4993, -0.1286)  epsilon: 0.0176\n",
      "episode: 215   score: -96.8724   time_steps: 313  landing_ops_time: 519.9   landing_coord: (0.2009, -0.042)  epsilon: 0.017\n",
      "episode: 216   score: -52.1752   time_steps: 80  landing_ops_time: 451.1   landing_coord: (-0.6223, -0.2189)  epsilon: 0.0169\n",
      "episode: 217   score: 28.8729   time_steps: 66  landing_ops_time: 378.7   landing_coord: (-0.0306, -0.043)  epsilon: 0.0168\n",
      "episode: 218   score: -28.0834   time_steps: 78  landing_ops_time: 377.1   landing_coord: (0.4864, 0.0461)  epsilon: 0.0167\n",
      "episode: 219   score: -352.8447   time_steps: 335  landing_ops_time: 284.8   landing_coord: (1.0001, 0.4803)  epsilon: 0.0161\n",
      "episode: 220   score: -246.5741   time_steps: 306  landing_ops_time: 298.7   landing_coord: (0.5556, 0.019)  epsilon: 0.0156\n",
      "episode: 221   score: -4240.8205   time_steps: 968  landing_ops_time: 302.4   landing_coord: (0.3294, -0.0593)  epsilon: 0.0142\n",
      "episode: 222   score: -87.0848   time_steps: 68  landing_ops_time: 326.9   landing_coord: (-0.5289, -0.1188)  epsilon: 0.0141\n",
      "episode: 223   score: -1478.3729   time_steps: 555  landing_ops_time: 312.6   landing_coord: (-0.1606, 0.0056)  epsilon: 0.0133\n",
      "episode: 224   score: -2178.8477   time_steps: 584  landing_ops_time: 268.0   landing_coord: (1.0045, -0.2756)  epsilon: 0.0126\n",
      "episode: 225   score: -71.8866   time_steps: 65  landing_ops_time: 315.3   landing_coord: (0.4307, 0.0914)  epsilon: 0.0125\n",
      "episode: 226   score: -1182.1161   time_steps: 433  landing_ops_time: 290.5   landing_coord: (-0.5206, -0.2015)  epsilon: 0.012\n",
      "episode: 227   score: -36.4871   time_steps: 188  landing_ops_time: 325.8   landing_coord: (0.9944, -0.0836)  epsilon: 0.0118\n",
      "episode: 228   score: -2026.0442   time_steps: 602  landing_ops_time: 338.0   landing_coord: (-0.3323, -0.0551)  epsilon: 0.0111\n",
      "episode: 229   score: -3291.5537   time_steps: 768  landing_ops_time: 390.4   landing_coord: (-1.0078, -0.4158)  epsilon: 0.0103\n",
      "episode: 230   score: -3271.8566   time_steps: 847  landing_ops_time: 433.7   landing_coord: (-0.565, 0.0203)  epsilon: 0.0094\n",
      "episode: 231   score: -155.9751   time_steps: 369  landing_ops_time: 487.8   landing_coord: (0.4407, -0.0939)  epsilon: 0.0091\n",
      "episode: 232   score: -2172.2658   time_steps: 668  landing_ops_time: 427.9   landing_coord: (-0.4366, 0.0511)  epsilon: 0.0085\n",
      "episode: 233   score: -28.2928   time_steps: 64  landing_ops_time: 487.9   landing_coord: (-0.4014, 0.0533)  epsilon: 0.0084\n",
      "episode: 234   score: -54.1684   time_steps: 70  landing_ops_time: 438.8   landing_coord: (0.4716, -0.1083)  epsilon: 0.0084\n",
      "episode: 235   score: -839.2012   time_steps: 484  landing_ops_time: 387.4   landing_coord: (-0.5865, -0.1943)  epsilon: 0.008\n",
      "episode: 236   score: -395.9146   time_steps: 427  landing_ops_time: 429.3   landing_coord: (0.0031, -0.0007)  epsilon: 0.0077\n",
      "episode: 237   score: -2224.8171   time_steps: 720  landing_ops_time: 428.7   landing_coord: (0.7434, -0.1891)  epsilon: 0.0071\n",
      "episode: 238   score: 212.1122   time_steps: 210  landing_ops_time: 481.9   landing_coord: (0.3239, -0.037)  epsilon: 0.007\n",
      "episode: 239   score: -21.8306   time_steps: 78  landing_ops_time: 442.7   landing_coord: (0.4213, -0.0044)  epsilon: 0.0069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 240   score: -2582.2964   time_steps: 797  landing_ops_time: 373.7   landing_coord: (0.2735, 0.0208)  epsilon: 0.0064\n",
      "episode: 241   score: -35.0196   time_steps: 94  landing_ops_time: 368.7   landing_coord: (0.4466, -0.0768)  epsilon: 0.0063\n",
      "episode: 242   score: 296.2806   time_steps: 253  landing_ops_time: 341.2   landing_coord: (-0.0339, -0.0006)  epsilon: 0.0062\n",
      "episode: 243   score: -24.2485   time_steps: 83  landing_ops_time: 299.7   landing_coord: (-0.3184, 0.0413)  epsilon: 0.0061\n",
      "episode: 244   score: -1663.4875   time_steps: 572  landing_ops_time: 301.6   landing_coord: (0.4455, 0.0541)  epsilon: 0.0058\n",
      "episode: 245   score: -574.1717   time_steps: 448  landing_ops_time: 351.8   landing_coord: (0.2336, 0.0373)  epsilon: 0.0055\n",
      "episode: 246   score: -154.2729   time_steps: 138  landing_ops_time: 348.2   landing_coord: (-0.2971, -0.0236)  epsilon: 0.0055\n",
      "episode: 247   score: -84.0211   time_steps: 72  landing_ops_time: 319.3   landing_coord: (-0.524, -0.1583)  epsilon: 0.0054\n",
      "episode: 248   score: -412.8981   time_steps: 385  landing_ops_time: 254.5   landing_coord: (0.3628, -0.0582)  epsilon: 0.0052\n",
      "episode: 249   score: 24.7812   time_steps: 96  landing_ops_time: 272.0   landing_coord: (0.2738, 0.0284)  epsilon: 0.0052\n",
      "episode: 250   score: -1002.4866   time_steps: 485  landing_ops_time: 273.8   landing_coord: (0.2584, 0.0397)  epsilon: 0.0049\n",
      "episode: 251   score: 52.4913   time_steps: 190  landing_ops_time: 242.6   landing_coord: (-0.0451, -0.0301)  epsilon: 0.0048\n",
      "episode: 252   score: -1581.2683   time_steps: 531  landing_ops_time: 252.2   landing_coord: (0.2048, -0.0419)  epsilon: 0.0046\n",
      "episode: 253   score: 190.402   time_steps: 286  landing_ops_time: 280.0   landing_coord: (0.2137, 0.038)  epsilon: 0.0045\n",
      "episode: 254   score: -30.6167   time_steps: 98  landing_ops_time: 300.3   landing_coord: (0.5999, -0.0852)  epsilon: 0.0044\n",
      "episode: 255   score: -17.8863   time_steps: 97  landing_ops_time: 252.9   landing_coord: (-0.3715, -0.1508)  epsilon: 0.0044\n",
      "episode: 256   score: -4975.6329   time_steps: 1001  landing_ops_time: 217.8   landing_coord: (0.7521, 0.0286)  epsilon: 0.004\n",
      "episode: 257   score: -3156.4141   time_steps: 789  landing_ops_time: 304.1   landing_coord: (0.6676, -0.1152)  epsilon: 0.0037\n",
      "episode: 258   score: -3.8888   time_steps: 141  landing_ops_time: 375.8   landing_coord: (-0.3308, -0.0552)  epsilon: 0.0036\n",
      "episode: 259   score: -18.4982   time_steps: 70  landing_ops_time: 351.4   landing_coord: (0.4365, 0.0059)  epsilon: 0.0036\n",
      "episode: 260   score: 61.2237   time_steps: 192  landing_ops_time: 348.8   landing_coord: (-0.1737, -0.0377)  epsilon: 0.0035\n",
      "episode: 261   score: -1797.5865   time_steps: 598  landing_ops_time: 319.5   landing_coord: (0.2045, -0.0213)  epsilon: 0.0033\n",
      "episode: 262   score: -1334.5178   time_steps: 559  landing_ops_time: 360.3   landing_coord: (0.0276, -0.0003)  epsilon: 0.0031\n",
      "episode: 263   score: -603.0435   time_steps: 437  landing_ops_time: 363.1   landing_coord: (0.081, -0.0009)  epsilon: 0.003\n",
      "episode: 264   score: -70.6516   time_steps: 84  landing_ops_time: 378.2   landing_coord: (-0.3595, -0.0082)  epsilon: 0.003\n",
      "episode: 265   score: 38.3918   time_steps: 69  landing_ops_time: 376.8   landing_coord: (0.0947, -0.0428)  epsilon: 0.0029\n",
      "episode: 266   score: 302.4069   time_steps: 301  landing_ops_time: 374.0   landing_coord: (-0.0515, -0.0009)  epsilon: 0.0029\n",
      "episode: 267   score: 24.034   time_steps: 86  landing_ops_time: 304.0   landing_coord: (0.5532, 0.103)  epsilon: 0.0028\n",
      "episode: 268   score: -48.7237   time_steps: 62  landing_ops_time: 233.7   landing_coord: (0.4731, 0.0157)  epsilon: 0.0028\n",
      "episode: 269   score: 28.1716   time_steps: 113  landing_ops_time: 225.8   landing_coord: (0.4782, -0.1061)  epsilon: 0.0028\n",
      "episode: 270   score: -33.5086   time_steps: 205  landing_ops_time: 230.1   landing_coord: (-0.2471, 0.0099)  epsilon: 0.0027\n",
      "episode: 271   score: -47.2316   time_steps: 152  landing_ops_time: 231.4   landing_coord: (-0.3068, 0.0438)  epsilon: 0.0027\n",
      "episode: 272   score: -58.9476   time_steps: 221  landing_ops_time: 186.8   landing_coord: (-0.1495, -0.0287)  epsilon: 0.0026\n",
      "episode: 273   score: -0.0674   time_steps: 133  landing_ops_time: 153.0   landing_coord: (0.2109, -0.0394)  epsilon: 0.0026\n",
      "episode: 274   score: -52.8119   time_steps: 119  landing_ops_time: 122.6   landing_coord: (-0.3558, 0.0843)  epsilon: 0.0026\n",
      "episode: 275   score: -15.0608   time_steps: 92  landing_ops_time: 126.1   landing_coord: (-0.6255, 0.0785)  epsilon: 0.0025\n",
      "episode: 276   score: 97.0911   time_steps: 272  landing_ops_time: 128.4   landing_coord: (0.0976, -0.001)  epsilon: 0.0025\n",
      "episode: 277   score: -47.5308   time_steps: 157  landing_ops_time: 125.5   landing_coord: (-0.4165, -0.0682)  epsilon: 0.0024\n",
      "episode: 278   score: -23.988   time_steps: 178  landing_ops_time: 132.6   landing_coord: (-0.0377, -0.0275)  epsilon: 0.0024\n",
      "episode: 279   score: -38.5542   time_steps: 66  landing_ops_time: 144.2   landing_coord: (0.415, -0.1145)  epsilon: 0.0024\n",
      "episode: 280   score: -1480.6929   time_steps: 476  landing_ops_time: 139.5   landing_coord: (-0.0646, -0.0286)  epsilon: 0.0023\n",
      "episode: 281   score: -26.9136   time_steps: 91  landing_ops_time: 166.6   landing_coord: (0.4172, 0.1061)  epsilon: 0.0022\n",
      "episode: 282   score: -1829.9287   time_steps: 596  landing_ops_time: 160.5   landing_coord: (-0.0078, -0.0005)  epsilon: 0.0021\n",
      "episode: 283   score: -7.5311   time_steps: 111  landing_ops_time: 198.0   landing_coord: (0.3245, 0.0545)  epsilon: 0.0021\n",
      "episode: 284   score: -671.0164   time_steps: 378  landing_ops_time: 195.8   landing_coord: (-0.4367, -0.1267)  epsilon: 0.002\n",
      "episode: 285   score: 119.0124   time_steps: 289  landing_ops_time: 221.7   landing_coord: (0.009, -0.0009)  epsilon: 0.002\n",
      "episode: 286   score: -6.2884   time_steps: 179  landing_ops_time: 241.4   landing_coord: (-0.1056, -0.0289)  epsilon: 0.0019\n",
      "episode: 287   score: -175.7584   time_steps: 157  landing_ops_time: 232.1   landing_coord: (-0.4251, -0.1266)  epsilon: 0.0019\n",
      "episode: 288   score: -328.3942   time_steps: 333  landing_ops_time: 232.1   landing_coord: (0.0178, -0.0279)  epsilon: 0.0018\n",
      "episode: 289   score: -400.6543   time_steps: 329  landing_ops_time: 247.6   landing_coord: (-0.4301, -0.1379)  epsilon: 0.0018\n",
      "episode: 290   score: -60.7217   time_steps: 66  landing_ops_time: 273.9   landing_coord: (-0.403, 0.0868)  epsilon: 0.0018\n",
      "episode: 291   score: -40.573   time_steps: 71  landing_ops_time: 232.9   landing_coord: (-0.4553, -0.0836)  epsilon: 0.0018\n",
      "episode: 292   score: -55.9636   time_steps: 60  landing_ops_time: 230.9   landing_coord: (-0.3916, 0.121)  epsilon: 0.0017\n",
      "episode: 293   score: -74.9117   time_steps: 64  landing_ops_time: 177.3   landing_coord: (0.5111, -0.0768)  epsilon: 0.0017\n",
      "episode: 294   score: -321.6909   time_steps: 325  landing_ops_time: 172.6   landing_coord: (-0.1018, -0.0288)  epsilon: 0.0017\n",
      "episode: 295   score: -4755.0591   time_steps: 1001  landing_ops_time: 167.3   landing_coord: (0.0096, 0.0948)  epsilon: 0.0015\n",
      "episode: 296   score: -94.3324   time_steps: 92  landing_ops_time: 238.5   landing_coord: (0.7358, -0.118)  epsilon: 0.0015\n",
      "episode: 297   score: -1724.3305   time_steps: 585  landing_ops_time: 229.8   landing_coord: (-0.1049, -0.0009)  epsilon: 0.0014\n",
      "episode: 298   score: -65.1392   time_steps: 85  landing_ops_time: 272.6   landing_coord: (-0.5908, 0.0905)  epsilon: 0.0014\n",
      "episode: 299   score: -144.8733   time_steps: 293  landing_ops_time: 247.8   landing_coord: (-0.2461, -0.0652)  epsilon: 0.0014\n",
      "episode: 300   score: -15.0762   time_steps: 289  landing_ops_time: 244.2   landing_coord: (-0.2303, -0.0124)  epsilon: 0.0013\n",
      "episode: 301   score: -46.6234   time_steps: 185  landing_ops_time: 266.5   landing_coord: (-0.7268, 0.1414)  epsilon: 0.0013\n",
      "episode: 302   score: -82.8759   time_steps: 209  landing_ops_time: 277.9   landing_coord: (-0.5127, -0.1809)  epsilon: 0.0013\n",
      "episode: 303   score: -3412.8616   time_steps: 823  landing_ops_time: 292.8   landing_coord: (-0.0347, -0.0275)  epsilon: 0.0012\n",
      "episode: 304   score: -27.6668   time_steps: 203  landing_ops_time: 368.7   landing_coord: (0.3205, -0.0515)  epsilon: 0.0012\n",
      "episode: 305   score: -737.8236   time_steps: 448  landing_ops_time: 356.5   landing_coord: (-0.4609, -0.0468)  epsilon: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 306   score: -60.5776   time_steps: 252  landing_ops_time: 301.2   landing_coord: (0.3326, -0.1238)  epsilon: 0.0011\n",
      "episode: 307   score: -462.749   time_steps: 323  landing_ops_time: 317.2   landing_coord: (-0.9494, -0.3579)  epsilon: 0.001\n",
      "episode: 308   score: -209.7368   time_steps: 97  landing_ops_time: 291.0   landing_coord: (0.2116, 0.0026)  epsilon: 0.001\n",
      "episode: 309   score: -2116.5327   time_steps: 592  landing_ops_time: 292.2   landing_coord: (0.8214, -0.0604)  epsilon: 0.001\n",
      "episode: 310   score: -214.0102   time_steps: 287  landing_ops_time: 322.1   landing_coord: (-0.6134, 0.0608)  epsilon: 0.0009\n",
      "episode: 311   score: -672.6297   time_steps: 371  landing_ops_time: 321.9   landing_coord: (-1.0026, 1.0345)  epsilon: 0.0009\n",
      "episode: 312   score: -607.1987   time_steps: 377  landing_ops_time: 340.5   landing_coord: (-0.8358, -0.2318)  epsilon: 0.0009\n",
      "episode: 313   score: -30.3291   time_steps: 66  landing_ops_time: 357.3   landing_coord: (0.474, -0.0341)  epsilon: 0.0009\n",
      "episode: 314   score: -156.7228   time_steps: 361  landing_ops_time: 281.6   landing_coord: (-0.0956, -1e-04)  epsilon: 0.0008\n",
      "episode: 315   score: -124.8445   time_steps: 253  landing_ops_time: 297.4   landing_coord: (-1.0035, 0.4765)  epsilon: 0.0008\n",
      "episode: 316   score: -787.3438   time_steps: 383  landing_ops_time: 277.9   landing_coord: (-1.0038, 0.6176)  epsilon: 0.0008\n",
      "episode: 317   score: -113.3139   time_steps: 201  landing_ops_time: 291.0   landing_coord: (1.001, 1.0533)  epsilon: 0.0008\n",
      "episode: 318   score: -2192.5497   time_steps: 595  landing_ops_time: 278.8   landing_coord: (0.6364, -0.2729)  epsilon: 0.0007\n",
      "episode: 319   score: -36.1626   time_steps: 285  landing_ops_time: 328.6   landing_coord: (-0.318, -0.004)  epsilon: 0.0007\n",
      "episode: 320   score: -51.8   time_steps: 245  landing_ops_time: 297.9   landing_coord: (0.1927, -0.0387)  epsilon: 0.0007\n",
      "episode: 321   score: -13.5946   time_steps: 213  landing_ops_time: 293.7   landing_coord: (0.2523, -0.0246)  epsilon: 0.0007\n",
      "episode: 322   score: -4686.1898   time_steps: 1001  landing_ops_time: 277.9   landing_coord: (-0.8503, 0.5675)  epsilon: 0.0006\n",
      "episode: 323   score: 41.6949   time_steps: 87  landing_ops_time: 340.3   landing_coord: (0.1119, -0.0292)  epsilon: 0.0006\n",
      "episode: 324   score: -406.6471   time_steps: 335  landing_ops_time: 342.4   landing_coord: (1.0006, 1.8114)  epsilon: 0.0006\n",
      "episode: 325   score: 7.6829   time_steps: 77  landing_ops_time: 339.8   landing_coord: (0.4642, -0.0685)  epsilon: 0.0006\n",
      "episode: 326   score: 256.2586   time_steps: 242  landing_ops_time: 322.2   landing_coord: (0.3747, -0.0318)  epsilon: 0.0006\n",
      "episode: 327   score: -2185.7789   time_steps: 650  landing_ops_time: 308.1   landing_coord: (-0.5259, -0.0366)  epsilon: 0.0005\n",
      "episode: 328   score: 60.9253   time_steps: 157  landing_ops_time: 353.0   landing_coord: (-0.1036, -0.0362)  epsilon: 0.0005\n",
      "episode: 329   score: -1141.1184   time_steps: 430  landing_ops_time: 309.2   landing_coord: (1.0023, 2.1068)  epsilon: 0.0005\n",
      "episode: 330   score: 63.6489   time_steps: 180  landing_ops_time: 323.7   landing_coord: (0.2194, -0.0437)  epsilon: 0.0005\n",
      "episode: 331   score: -1004.1811   time_steps: 415  landing_ops_time: 317.2   landing_coord: (1.0002, 1.7536)  epsilon: 0.0005\n",
      "episode: 332   score: -560.6196   time_steps: 423  landing_ops_time: 337.4   landing_coord: (-0.1453, 0.014)  epsilon: 0.0005\n",
      "episode: 333   score: -2543.0962   time_steps: 706  landing_ops_time: 279.6   landing_coord: (-0.1205, 0.0006)  epsilon: 0.0004\n",
      "episode: 334   score: -59.2714   time_steps: 109  landing_ops_time: 341.5   landing_coord: (0.3345, -0.0017)  epsilon: 0.0004\n",
      "episode: 335   score: -13.6835   time_steps: 81  landing_ops_time: 318.9   landing_coord: (-0.5556, 0.0351)  epsilon: 0.0004\n",
      "episode: 336   score: -2291.2962   time_steps: 600  landing_ops_time: 319.3   landing_coord: (1.0, 1.931)  epsilon: 0.0004\n",
      "episode: 337   score: -4442.575   time_steps: 1001  landing_ops_time: 355.1   landing_coord: (-0.1616, 0.1479)  epsilon: 0.0004\n",
      "episode: 338   score: -359.1596   time_steps: 408  landing_ops_time: 390.2   landing_coord: (0.076, -0.0005)  epsilon: 0.0003\n",
      "episode: 339   score: 24.7746   time_steps: 348  landing_ops_time: 415.3   landing_coord: (0.0015, -0.0006)  epsilon: 0.0003\n",
      "episode: 340   score: 1.1137   time_steps: 219  landing_ops_time: 407.1   landing_coord: (-0.2175, -0.0229)  epsilon: 0.0003\n",
      "episode: 341   score: -25.1723   time_steps: 186  landing_ops_time: 411.0   landing_coord: (-0.2972, -0.0529)  epsilon: 0.0003\n",
      "episode: 342   score: -169.3195   time_steps: 85  landing_ops_time: 388.1   landing_coord: (0.4149, 0.1025)  epsilon: 0.0003\n",
      "episode: 343   score: -357.215   time_steps: 359  landing_ops_time: 354.3   landing_coord: (0.4669, 0.0425)  epsilon: 0.0003\n",
      "episode: 344   score: 1.7081   time_steps: 130  landing_ops_time: 319.6   landing_coord: (-0.3506, -0.0851)  epsilon: 0.0003\n",
      "episode: 345   score: -1009.4695   time_steps: 445  landing_ops_time: 321.7   landing_coord: (0.5658, 0.111)  epsilon: 0.0003\n",
      "episode: 346   score: -3887.2286   time_steps: 924  landing_ops_time: 358.1   landing_coord: (-0.1139, -0.0011)  epsilon: 0.0003\n",
      "episode: 347   score: -2860.6646   time_steps: 739  landing_ops_time: 390.5   landing_coord: (0.3512, 0.0379)  epsilon: 0.0002\n",
      "episode: 348   score: -2979.3996   time_steps: 775  landing_ops_time: 364.3   landing_coord: (-0.1514, 0.0047)  epsilon: 0.0002\n",
      "episode: 349   score: 231.8331   time_steps: 249  landing_ops_time: 401.0   landing_coord: (0.3407, 0.0122)  epsilon: 0.0002\n",
      "episode: 350   score: -29.3879   time_steps: 112  landing_ops_time: 391.1   landing_coord: (0.5705, -0.0072)  epsilon: 0.0002\n",
      "episode: 351   score: -4588.9898   time_steps: 955  landing_ops_time: 380.4   landing_coord: (1.0006, 1.4599)  epsilon: 0.0002\n",
      "episode: 352   score: -108.482   time_steps: 81  landing_ops_time: 457.3   landing_coord: (0.6791, -0.1819)  epsilon: 0.0002\n",
      "episode: 353   score: 57.5464   time_steps: 330  landing_ops_time: 456.9   landing_coord: (0.3751, 0.0268)  epsilon: 0.0002\n",
      "episode: 354   score: -3843.8432   time_steps: 923  landing_ops_time: 454.0   landing_coord: (0.5507, 0.0361)  epsilon: 0.0002\n",
      "episode: 355   score: -29.0646   time_steps: 127  landing_ops_time: 533.3   landing_coord: (0.679, -0.1244)  epsilon: 0.0002\n",
      "episode: 356   score: -4215.7374   time_steps: 1001  landing_ops_time: 501.5   landing_coord: (0.33, 0.2151)  epsilon: 0.0002\n",
      "episode: 357   score: -51.8337   time_steps: 115  landing_ops_time: 509.2   landing_coord: (0.6882, 0.0081)  epsilon: 0.0002\n",
      "episode: 358   score: -2185.7966   time_steps: 685  landing_ops_time: 446.8   landing_coord: (0.335, -0.0671)  epsilon: 0.0001\n",
      "episode: 359   score: 27.1183   time_steps: 109  landing_ops_time: 437.8   landing_coord: (0.7405, 0.069)  epsilon: 0.0001\n",
      "episode: 360   score: -26.9367   time_steps: 102  landing_ops_time: 423.8   landing_coord: (0.5576, 0.1213)  epsilon: 0.0001\n",
      "episode: 361   score: -705.8696   time_steps: 458  landing_ops_time: 422.8   landing_coord: (0.5452, -0.1932)  epsilon: 0.0001\n",
      "episode: 362   score: -1161.1611   time_steps: 513  landing_ops_time: 373.1   landing_coord: (0.4043, -0.0861)  epsilon: 0.0001\n",
      "episode: 363   score: -4695.9183   time_steps: 1001  landing_ops_time: 416.3   landing_coord: (-0.4471, 0.6019)  epsilon: 0.0001\n",
      "episode: 364   score: -104.7053   time_steps: 176  landing_ops_time: 483.4   landing_coord: (-0.807, -0.0406)  epsilon: 0.0001\n",
      "episode: 365   score: -232.5816   time_steps: 249  landing_ops_time: 408.7   landing_coord: (0.8391, -0.2965)  epsilon: 0.0001\n",
      "episode: 366   score: -147.7938   time_steps: 141  landing_ops_time: 420.9   landing_coord: (0.4659, -0.1284)  epsilon: 0.0001\n",
      "episode: 367   score: -59.3067   time_steps: 64  landing_ops_time: 334.9   landing_coord: (-0.4718, 0.0352)  epsilon: 0.0001\n",
      "episode: 368   score: -33.2268   time_steps: 153  landing_ops_time: 329.8   landing_coord: (0.0605, -0.0334)  epsilon: 0.0001\n",
      "episode: 369   score: -656.7567   time_steps: 372  landing_ops_time: 276.6   landing_coord: (0.9223, -0.3644)  epsilon: 0.0001\n",
      "episode: 370   score: 202.0594   time_steps: 197  landing_ops_time: 302.9   landing_coord: (0.6605, 0.0687)  epsilon: 0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 371   score: -4692.5545   time_steps: 1001  landing_ops_time: 312.4   landing_coord: (-0.3133, 0.72)  epsilon: 0.0001\n",
      "episode: 372   score: -72.8167   time_steps: 71  landing_ops_time: 366.7   landing_coord: (0.505, 0.0393)  epsilon: 0.0001\n",
      "episode: 373   score: -357.0753   time_steps: 111  landing_ops_time: 322.5   landing_coord: (-0.0635, 0.0142)  epsilon: 0.0001\n",
      "episode: 374   score: -297.4469   time_steps: 131  landing_ops_time: 233.5   landing_coord: (0.0521, 0.0174)  epsilon: 0.0001\n",
      "episode: 375   score: -127.1716   time_steps: 121  landing_ops_time: 229.0   landing_coord: (-0.135, 0.006)  epsilon: 0.0001\n",
      "episode: 376   score: -108.1989   time_steps: 196  landing_ops_time: 216.2   landing_coord: (0.7249, -0.2827)  epsilon: 0.0001\n",
      "episode: 377   score: -20.2641   time_steps: 151  landing_ops_time: 221.7   landing_coord: (0.9779, 0.0799)  epsilon: 0.0001\n",
      "episode: 378   score: -45.2533   time_steps: 220  landing_ops_time: 230.4   landing_coord: (0.5488, 0.0648)  epsilon: 0.0001\n",
      "episode: 379   score: -31.8329   time_steps: 131  landing_ops_time: 237.1   landing_coord: (-0.1301, -0.0381)  epsilon: 0.0001\n",
      "episode: 380   score: -161.1819   time_steps: 264  landing_ops_time: 213.0   landing_coord: (0.8668, -0.23)  epsilon: 0.0001\n",
      "episode: 381   score: -2198.4167   time_steps: 626  landing_ops_time: 219.7   landing_coord: (0.2475, -0.0237)  epsilon: 0.0001\n",
      "episode: 382   score: -513.0985   time_steps: 285  landing_ops_time: 182.2   landing_coord: (-0.4112, -0.1173)  epsilon: 0.0001\n",
      "episode: 383   score: -4486.6548   time_steps: 1001  landing_ops_time: 203.6   landing_coord: (-0.0848, -0.0031)  epsilon: 0.0001\n",
      "episode: 384   score: -76.1843   time_steps: 128  landing_ops_time: 292.6   landing_coord: (0.5415, 0.083)  epsilon: 0.0001\n",
      "episode: 385   score: -47.8206   time_steps: 70  landing_ops_time: 292.3   landing_coord: (-0.5719, 0.0812)  epsilon: 0.0001\n",
      "episode: 386   score: -3293.1281   time_steps: 813  landing_ops_time: 287.2   landing_coord: (0.6896, -0.1338)  epsilon: 0.0001\n",
      "episode: 387   score: -240.0673   time_steps: 329  landing_ops_time: 348.9   landing_coord: (0.9256, -0.0633)  epsilon: 0.0001\n",
      "episode: 388   score: -1224.1988   time_steps: 527  landing_ops_time: 366.7   landing_coord: (-0.1233, 0.0014)  epsilon: 0.0001\n",
      "episode: 389   score: -152.3369   time_steps: 369  landing_ops_time: 397.4   landing_coord: (0.1907, -0.0187)  epsilon: 0.0001\n",
      "episode: 390   score: -256.2646   time_steps: 150  landing_ops_time: 421.2   landing_coord: (-0.5054, -0.0571)  epsilon: 0.0001\n",
      "episode: 391   score: -363.942   time_steps: 93  landing_ops_time: 409.8   landing_coord: (0.1756, 0.0173)  epsilon: 0.0001\n",
      "episode: 392   score: 268.1948   time_steps: 139  landing_ops_time: 356.5   landing_coord: (0.1022, -0.0003)  epsilon: 0.0\n",
      "episode: 393   score: 14.7507   time_steps: 199  landing_ops_time: 341.9   landing_coord: (0.2787, -0.0323)  epsilon: 0.0\n",
      "episode: 394   score: -32.5896   time_steps: 263  landing_ops_time: 261.7   landing_coord: (0.3953, 0.0156)  epsilon: 0.0\n",
      "episode: 395   score: -55.2483   time_steps: 277  landing_ops_time: 275.2   landing_coord: (0.2844, 0.0296)  epsilon: 0.0\n",
      "episode: 396   score: -19.8537   time_steps: 179  landing_ops_time: 295.9   landing_coord: (-0.3927, -0.049)  epsilon: 0.0\n",
      "episode: 397   score: -44.1916   time_steps: 98  landing_ops_time: 232.5   landing_coord: (0.6501, -0.1137)  epsilon: 0.0\n",
      "episode: 398   score: -229.3566   time_steps: 340  landing_ops_time: 209.4   landing_coord: (0.2189, 0.0414)  epsilon: 0.0\n",
      "episode: 399   score: -3208.5085   time_steps: 804  landing_ops_time: 190.7   landing_coord: (-0.5062, 0.0351)  epsilon: 0.0\n",
      "episode: 400   score: -166.8081   time_steps: 355  landing_ops_time: 234.2   landing_coord: (0.6793, -0.2312)  epsilon: 0.0\n",
      "episode: 401   score: -145.8876   time_steps: 74  landing_ops_time: 254.7   landing_coord: (0.7546, -0.1944)  epsilon: 0.0\n",
      "episode: 402   score: 32.277   time_steps: 310  landing_ops_time: 252.8   landing_coord: (0.2662, 0.016)  epsilon: 0.0\n",
      "episode: 403   score: -78.9432   time_steps: 70  landing_ops_time: 269.9   landing_coord: (-0.5861, -0.2375)  epsilon: 0.0\n",
      "episode: 404   score: -4823.182   time_steps: 1001  landing_ops_time: 257.0   landing_coord: (-0.4442, 0.0238)  epsilon: 0.0\n",
      "episode: 405   score: 186.4973   time_steps: 203  landing_ops_time: 330.8   landing_coord: (0.7159, -0.1823)  epsilon: 0.0\n",
      "episode: 406   score: -108.5663   time_steps: 56  landing_ops_time: 323.4   landing_coord: (0.4932, 0.1385)  epsilon: 0.0\n",
      "episode: 407   score: -5.167   time_steps: 126  landing_ops_time: 311.1   landing_coord: (0.1251, -0.0397)  epsilon: 0.0\n",
      "episode: 408   score: -32.1569   time_steps: 138  landing_ops_time: 313.9   landing_coord: (0.2921, 0.0401)  epsilon: 0.0\n",
      "episode: 409   score: -1153.7443   time_steps: 490  landing_ops_time: 293.7   landing_coord: (-0.3555, -0.0407)  epsilon: 0.0\n",
      "episode: 410   score: 194.1144   time_steps: 288  landing_ops_time: 262.3   landing_coord: (-0.1177, 0.0025)  epsilon: 0.0\n",
      "episode: 411   score: -31.2722   time_steps: 203  landing_ops_time: 255.6   landing_coord: (-0.2954, -0.1027)  epsilon: 0.0\n",
      "episode: 412   score: -0.7007   time_steps: 90  landing_ops_time: 268.5   landing_coord: (0.2253, -0.0464)  epsilon: 0.0\n",
      "episode: 413   score: -1651.0725   time_steps: 573  landing_ops_time: 246.5   landing_coord: (0.1821, -0.0087)  epsilon: 0.0\n",
      "episode: 414   score: -882.0498   time_steps: 457  landing_ops_time: 296.8   landing_coord: (0.0865, -0.0007)  epsilon: 0.0\n",
      "episode: 415   score: -587.0915   time_steps: 409  landing_ops_time: 242.4   landing_coord: (0.7095, -0.2156)  epsilon: 0.0\n",
      "episode: 416   score: -494.5851   time_steps: 390  landing_ops_time: 263.0   landing_coord: (0.3442, -0.1023)  epsilon: 0.0\n",
      "episode: 417   score: -31.6687   time_steps: 146  landing_ops_time: 296.4   landing_coord: (0.8343, 0.0576)  epsilon: 0.0\n",
      "episode: 418   score: -1126.4961   time_steps: 474  landing_ops_time: 298.4   landing_coord: (0.2338, -0.038)  epsilon: 0.0\n",
      "episode: 419   score: -677.8478   time_steps: 424  landing_ops_time: 332.0   landing_coord: (0.7321, -0.296)  epsilon: 0.0\n",
      "episode: 420   score: -840.5545   time_steps: 470  landing_ops_time: 325.4   landing_coord: (-0.0372, -0.0006)  epsilon: 0.0\n",
      "episode: 421   score: 97.7462   time_steps: 315  landing_ops_time: 343.6   landing_coord: (0.2321, 0.0432)  epsilon: 0.0\n",
      "episode: 422   score: -86.0054   time_steps: 69  landing_ops_time: 354.8   landing_coord: (0.6099, 0.171)  epsilon: 0.0\n",
      "episode: 423   score: -1048.4416   time_steps: 452  landing_ops_time: 352.7   landing_coord: (0.6802, 0.1037)  epsilon: 0.0\n",
      "episode: 424   score: -280.2078   time_steps: 139  landing_ops_time: 340.6   landing_coord: (-0.6146, -0.0813)  epsilon: 0.0\n",
      "episode: 425   score: -390.7989   time_steps: 330  landing_ops_time: 308.8   landing_coord: (0.8356, -0.2479)  epsilon: 0.0\n",
      "episode: 426   score: -74.728   time_steps: 291  landing_ops_time: 300.9   landing_coord: (-0.2544, 0.0186)  epsilon: 0.0\n",
      "episode: 427   score: -1933.0769   time_steps: 637  landing_ops_time: 291.0   landing_coord: (-0.1474, -0.011)  epsilon: 0.0\n",
      "episode: 428   score: -1478.2426   time_steps: 564  landing_ops_time: 340.1   landing_coord: (0.4762, -0.043)  epsilon: 0.0\n",
      "episode: 429   score: -66.7722   time_steps: 186  landing_ops_time: 349.1   landing_coord: (-0.5096, -0.0263)  epsilon: 0.0\n",
      "episode: 430   score: 184.6269   time_steps: 315  landing_ops_time: 325.3   landing_coord: (-0.0846, -0.0011)  epsilon: 0.0\n",
      "episode: 431   score: -203.8686   time_steps: 170  landing_ops_time: 309.8   landing_coord: (-0.5032, 0.0127)  epsilon: 0.0\n",
      "episode: 432   score: -4422.8215   time_steps: 1001  landing_ops_time: 295.3   landing_coord: (0.0492, -0.0004)  epsilon: 0.0\n",
      "episode: 433   score: 27.8424   time_steps: 125  landing_ops_time: 388.5   landing_coord: (0.3666, -0.0212)  epsilon: 0.0\n",
      "episode: 434   score: -4565.8975   time_steps: 1001  landing_ops_time: 355.8   landing_coord: (-0.1435, 1.1079)  epsilon: 0.0\n",
      "episode: 435   score: -125.1758   time_steps: 128  landing_ops_time: 442.0   landing_coord: (-0.3597, 0.1085)  epsilon: 0.0\n",
      "episode: 436   score: 198.6779   time_steps: 257  landing_ops_time: 421.8   landing_coord: (0.242, 0.0254)  epsilon: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 437   score: 87.5772   time_steps: 313  landing_ops_time: 418.4   landing_coord: (0.604, -0.1564)  epsilon: 0.0\n",
      "episode: 438   score: 185.0948   time_steps: 294  landing_ops_time: 386.0   landing_coord: (0.6859, -0.0584)  epsilon: 0.0\n",
      "episode: 439   score: 191.7304   time_steps: 281  landing_ops_time: 359.0   landing_coord: (0.2773, 0.019)  epsilon: 0.0\n",
      "episode: 440   score: 176.4644   time_steps: 186  landing_ops_time: 368.5   landing_coord: (0.7789, -0.0246)  epsilon: 0.0\n",
      "episode: 441   score: 175.9209   time_steps: 324  landing_ops_time: 355.6   landing_coord: (0.1122, -0.0008)  epsilon: 0.0\n",
      "episode: 442   score: -3785.1536   time_steps: 913  landing_ops_time: 371.0   landing_coord: (0.482, 0.0471)  epsilon: 0.0\n",
      "episode: 443   score: -4513.4337   time_steps: 1001  landing_ops_time: 362.2   landing_coord: (0.2012, -0.0007)  epsilon: 0.0\n",
      "episode: 444   score: -4637.9831   time_steps: 1001  landing_ops_time: 449.8   landing_coord: (-0.4205, -0.1125)  epsilon: 0.0\n",
      "episode: 445   score: 202.3979   time_steps: 268  landing_ops_time: 449.8   landing_coord: (-0.2651, -0.0498)  epsilon: 0.0\n",
      "episode: 446   score: -4231.0489   time_steps: 1001  landing_ops_time: 463.8   landing_coord: (0.0877, -0.001)  epsilon: 0.0\n",
      "episode: 447   score: -3501.1853   time_steps: 890  landing_ops_time: 538.2   landing_coord: (0.2246, -0.029)  epsilon: 0.0\n",
      "episode: 448   score: -794.9194   time_steps: 493  landing_ops_time: 595.9   landing_coord: (0.1137, -0.0005)  epsilon: 0.0\n",
      "episode: 449   score: -1804.7212   time_steps: 669  landing_ops_time: 615.8   landing_coord: (0.7064, -0.1281)  epsilon: 0.0\n",
      "episode: 450   score: -34.9785   time_steps: 79  landing_ops_time: 654.6   landing_coord: (-0.3741, 0.0193)  epsilon: 0.0\n",
      "episode: 451   score: -3249.295   time_steps: 817  landing_ops_time: 643.9   landing_coord: (1.0019, 1.1952)  epsilon: 0.0\n",
      "episode: 452   score: -2074.2198   time_steps: 742  landing_ops_time: 693.2   landing_coord: (-0.0541, -0.0008)  epsilon: 0.0\n",
      "episode: 453   score: -101.3408   time_steps: 230  landing_ops_time: 676.1   landing_coord: (0.8833, -0.3512)  epsilon: 0.0\n",
      "episode: 454   score: -2487.6408   time_steps: 703  landing_ops_time: 599.0   landing_coord: (1.0029, 1.2385)  epsilon: 0.0\n",
      "episode: 455   score: -3.857   time_steps: 111  landing_ops_time: 569.2   landing_coord: (-0.0766, -0.0374)  epsilon: 0.0\n",
      "episode: 456   score: -16.5228   time_steps: 139  landing_ops_time: 553.5   landing_coord: (-0.2044, -0.0432)  epsilon: 0.0\n",
      "episode: 457   score: 87.6431   time_steps: 75  landing_ops_time: 467.3   landing_coord: (-0.3937, -0.1351)  epsilon: 0.0\n",
      "episode: 458   score: -4833.2678   time_steps: 1001  landing_ops_time: 385.8   landing_coord: (0.458, 1.3157)  epsilon: 0.0\n",
      "episode: 459   score: -4665.6693   time_steps: 1001  landing_ops_time: 436.6   landing_coord: (0.2096, 0.8454)  epsilon: 0.0\n",
      "episode: 460   score: -2617.568   time_steps: 698  landing_ops_time: 469.8   landing_coord: (-0.4299, 0.0376)  epsilon: 0.0\n",
      "episode: 461   score: -29.5954   time_steps: 62  landing_ops_time: 531.7   landing_coord: (0.3135, 0.0476)  epsilon: 0.0\n",
      "episode: 462   score: -3924.3393   time_steps: 945  landing_ops_time: 456.2   landing_coord: (0.2072, 0.0275)  epsilon: 0.0\n",
      "episode: 463   score: -126.9408   time_steps: 90  landing_ops_time: 476.5   landing_coord: (-0.3172, -0.0232)  epsilon: 0.0\n",
      "episode: 464   score: -819.6883   time_steps: 422  landing_ops_time: 462.5   landing_coord: (1.0008, 1.3113)  epsilon: 0.0\n",
      "episode: 465   score: -1339.3594   time_steps: 501  landing_ops_time: 434.4   landing_coord: (1.0009, -0.0975)  epsilon: 0.0\n",
      "episode: 466   score: -259.8854   time_steps: 104  landing_ops_time: 473.4   landing_coord: (1.0187, 0.0537)  epsilon: 0.0\n",
      "episode: 467   score: -4486.7349   time_steps: 1001  landing_ops_time: 469.9   landing_coord: (0.13, 0.3069)  epsilon: 0.0\n",
      "episode: 468   score: -52.0229   time_steps: 69  landing_ops_time: 562.5   landing_coord: (0.3875, -0.0218)  epsilon: 0.0\n",
      "episode: 469   score: -140.3787   time_steps: 55  landing_ops_time: 469.3   landing_coord: (-0.3167, -0.1064)  epsilon: 0.0\n",
      "episode: 470   score: -126.8379   time_steps: 64  landing_ops_time: 374.7   landing_coord: (-0.3472, 0.0091)  epsilon: 0.0\n",
      "episode: 471   score: -365.3506   time_steps: 324  landing_ops_time: 311.3   landing_coord: (1.0052, -0.0924)  epsilon: 0.0\n",
      "episode: 472   score: 20.2449   time_steps: 109  landing_ops_time: 337.5   landing_coord: (-0.6051, 0.0106)  epsilon: 0.0\n",
      "episode: 473   score: -524.2828   time_steps: 171  landing_ops_time: 253.9   landing_coord: (0.4588, -0.0348)  epsilon: 0.0\n",
      "episode: 474   score: -230.0863   time_steps: 90  landing_ops_time: 262.0   landing_coord: (0.8668, 0.0451)  epsilon: 0.0\n",
      "episode: 475   score: -158.3404   time_steps: 135  landing_ops_time: 228.8   landing_coord: (1.0041, 1.0072)  epsilon: 0.0\n",
      "episode: 476   score: -197.117   time_steps: 112  landing_ops_time: 192.2   landing_coord: (1.0149, 0.0124)  epsilon: 0.0\n",
      "episode: 477   score: -646.7614   time_steps: 273  landing_ops_time: 193.0   landing_coord: (0.2499, 0.0378)  epsilon: 0.0\n",
      "episode: 478   score: -39.6301   time_steps: 105  landing_ops_time: 120.2   landing_coord: (0.4009, 0.1065)  epsilon: 0.0\n",
      "episode: 479   score: -568.6612   time_steps: 200  landing_ops_time: 123.8   landing_coord: (0.7226, -0.1561)  epsilon: 0.0\n",
      "episode: 480   score: -88.1285   time_steps: 64  landing_ops_time: 138.3   landing_coord: (-0.4, -0.1033)  epsilon: 0.0\n",
      "episode: 481   score: -316.0016   time_steps: 125  landing_ops_time: 138.3   landing_coord: (-0.0165, 0.009)  epsilon: 0.0\n",
      "episode: 482   score: -3322.738   time_steps: 719  landing_ops_time: 118.4   landing_coord: (0.4999, -0.0808)  epsilon: 0.0\n",
      "episode: 483   score: -126.5168   time_steps: 86  landing_ops_time: 179.4   landing_coord: (1.0075, -0.0017)  epsilon: 0.0\n",
      "episode: 484   score: -115.3553   time_steps: 54  landing_ops_time: 170.9   landing_coord: (-0.3262, 0.0418)  epsilon: 0.0\n",
      "episode: 485   score: -42.1292   time_steps: 195  landing_ops_time: 167.3   landing_coord: (0.7998, 0.1075)  epsilon: 0.0\n",
      "episode: 486   score: -517.387   time_steps: 359  landing_ops_time: 173.3   landing_coord: (0.4926, -0.0014)  epsilon: 0.0\n",
      "episode: 487   score: -429.2399   time_steps: 380  landing_ops_time: 198.0   landing_coord: (0.5363, -0.0645)  epsilon: 0.0\n",
      "episode: 488   score: -390.6188   time_steps: 370  landing_ops_time: 208.7   landing_coord: (-0.0613, -0.0007)  epsilon: 0.0\n",
      "episode: 489   score: -3495.0262   time_steps: 811  landing_ops_time: 235.2   landing_coord: (-0.0559, -0.0011)  epsilon: 0.0\n",
      "episode: 490   score: -947.6779   time_steps: 473  landing_ops_time: 296.3   landing_coord: (-0.0695, -0.0006)  epsilon: 0.0\n",
      "episode: 491   score: 271.5816   time_steps: 188  landing_ops_time: 337.2   landing_coord: (-0.02, -0.0005)  epsilon: 0.0\n",
      "episode: 492   score: -226.1908   time_steps: 140  landing_ops_time: 343.5   landing_coord: (0.0366, 0.0069)  epsilon: 0.0\n",
      "episode: 493   score: -1125.6077   time_steps: 498  landing_ops_time: 285.6   landing_coord: (0.1103, -0.0012)  epsilon: 0.0\n",
      "episode: 494   score: -41.4793   time_steps: 78  landing_ops_time: 326.8   landing_coord: (-0.4581, 0.0706)  epsilon: 0.0\n",
      "episode: 495   score: -131.3485   time_steps: 125  landing_ops_time: 329.2   landing_coord: (1.0008, 0.1791)  epsilon: 0.0\n",
      "episode: 496   score: -216.2954   time_steps: 119  landing_ops_time: 322.2   landing_coord: (-0.2475, 0.0078)  epsilon: 0.0\n",
      "episode: 497   score: 13.1924   time_steps: 113  landing_ops_time: 298.2   landing_coord: (0.0104, -0.0384)  epsilon: 0.0\n",
      "episode: 498   score: -1330.6805   time_steps: 481  landing_ops_time: 271.5   landing_coord: (1.0021, -0.238)  epsilon: 0.0\n",
      "episode: 499   score: 208.2933   time_steps: 247  landing_ops_time: 282.6   landing_coord: (0.4496, 0.1131)  epsilon: 0.0\n",
      "episode: 500   score: 8.3529   time_steps: 86  landing_ops_time: 226.2   landing_coord: (-0.5273, -0.2091)  epsilon: 0.0\n",
      "episode: 501   score: -1454.534   time_steps: 520  landing_ops_time: 187.5   landing_coord: (0.0837, -0.0008)  epsilon: 0.0\n",
      "episode: 502   score: -50.0087   time_steps: 72  landing_ops_time: 220.7   landing_coord: (-0.3207, -0.0868)  epsilon: 0.0\n",
      "episode: 503   score: -298.093   time_steps: 264  landing_ops_time: 213.9   landing_coord: (-0.2588, -0.0134)  epsilon: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 504   score: -56.1898   time_steps: 81  landing_ops_time: 190.5   landing_coord: (0.5298, 0.1951)  epsilon: 0.0\n",
      "episode: 505   score: -236.0711   time_steps: 122  landing_ops_time: 190.8   landing_coord: (-0.3143, -0.0524)  epsilon: 0.0\n",
      "episode: 506   score: -116.0478   time_steps: 115  landing_ops_time: 190.5   landing_coord: (1.0022, 0.2527)  epsilon: 0.0\n",
      "episode: 507   score: -1430.9094   time_steps: 510  landing_ops_time: 190.1   landing_coord: (0.0965, -0.0007)  epsilon: 0.0\n",
      "episode: 508   score: -128.4753   time_steps: 134  landing_ops_time: 229.8   landing_coord: (0.9868, -0.0041)  epsilon: 0.0\n",
      "episode: 509   score: 209.4923   time_steps: 232  landing_ops_time: 195.1   landing_coord: (-0.1223, -1e-04)  epsilon: 0.0\n",
      "episode: 510   score: -1867.2492   time_steps: 542  landing_ops_time: 193.6   landing_coord: (0.734, 0.1651)  epsilon: 0.0\n",
      "episode: 511   score: -214.3992   time_steps: 248  landing_ops_time: 239.2   landing_coord: (-0.2696, -0.0265)  epsilon: 0.0\n",
      "episode: 512   score: -1230.4245   time_steps: 440  landing_ops_time: 212.0   landing_coord: (0.7827, -0.1381)  epsilon: 0.0\n",
      "episode: 513   score: -72.3675   time_steps: 82  landing_ops_time: 248.8   landing_coord: (-0.6586, -0.129)  epsilon: 0.0\n",
      "episode: 514   score: -105.9193   time_steps: 186  landing_ops_time: 230.6   landing_coord: (0.8576, 0.1381)  epsilon: 0.0\n",
      "episode: 515   score: -54.9233   time_steps: 59  landing_ops_time: 241.1   landing_coord: (-0.3825, 0.0836)  epsilon: 0.0\n",
      "episode: 516   score: 137.8823   time_steps: 258  landing_ops_time: 234.8   landing_coord: (0.8399, -0.1926)  epsilon: 0.0\n",
      "episode: 517   score: -43.2748   time_steps: 79  landing_ops_time: 249.1   landing_coord: (-0.6199, 0.0543)  epsilon: 0.0\n",
      "episode: 518   score: -142.2796   time_steps: 132  landing_ops_time: 206.0   landing_coord: (1.0011, 0.9208)  epsilon: 0.0\n",
      "episode: 519   score: -114.862   time_steps: 88  landing_ops_time: 205.8   landing_coord: (0.789, 0.2096)  epsilon: 0.0\n",
      "episode: 520   score: -1111.8125   time_steps: 464  landing_ops_time: 191.4   landing_coord: (-0.2409, 0.012)  epsilon: 0.0\n",
      "episode: 521   score: -16.9096   time_steps: 113  landing_ops_time: 183.6   landing_coord: (-0.4882, -0.0932)  epsilon: 0.0\n",
      "episode: 522   score: -1841.641   time_steps: 527  landing_ops_time: 170.1   landing_coord: (0.0003, -0.0428)  epsilon: 0.0\n",
      "episode: 523   score: -270.06   time_steps: 248  landing_ops_time: 178.8   landing_coord: (0.9962, 0.148)  epsilon: 0.0\n",
      "episode: 524   score: -131.7718   time_steps: 138  landing_ops_time: 195.4   landing_coord: (1.0022, 0.9817)  epsilon: 0.0\n",
      "episode: 525   score: -2681.9252   time_steps: 638  landing_ops_time: 190.6   landing_coord: (0.2264, -0.0415)  epsilon: 0.0\n",
      "episode: 526   score: -69.8536   time_steps: 172  landing_ops_time: 248.5   landing_coord: (1.0021, 0.3846)  epsilon: 0.0\n",
      "episode: 527   score: 42.4282   time_steps: 317  landing_ops_time: 239.9   landing_coord: (-0.0156, -0.0011)  epsilon: 0.0\n",
      "episode: 528   score: -59.2712   time_steps: 82  landing_ops_time: 263.7   landing_coord: (-0.4957, 0.0549)  epsilon: 0.0\n",
      "episode: 529   score: -76.4203   time_steps: 196  landing_ops_time: 258.7   landing_coord: (0.7785, -0.0762)  epsilon: 0.0\n",
      "episode: 530   score: -136.6652   time_steps: 215  landing_ops_time: 269.5   landing_coord: (1.0004, 0.548)  epsilon: 0.0\n",
      "episode: 531   score: -172.4661   time_steps: 140  landing_ops_time: 244.6   landing_coord: (1.0013, 1.0478)  epsilon: 0.0\n",
      "episode: 532   score: -524.3477   time_steps: 325  landing_ops_time: 247.3   landing_coord: (-0.394, 0.0624)  epsilon: 0.0\n",
      "episode: 533   score: -151.8043   time_steps: 85  landing_ops_time: 227.1   landing_coord: (0.7674, -0.1395)  epsilon: 0.0\n",
      "episode: 534   score: -208.823   time_steps: 148  landing_ops_time: 210.8   landing_coord: (-1.0116, -0.325)  epsilon: 0.0\n",
      "episode: 535   score: -143.0329   time_steps: 117  landing_ops_time: 211.8   landing_coord: (1.0078, 0.6135)  epsilon: 0.0\n",
      "episode: 536   score: -137.3266   time_steps: 135  landing_ops_time: 159.7   landing_coord: (1.0054, 1.0212)  epsilon: 0.0\n",
      "episode: 537   score: -216.1416   time_steps: 117  landing_ops_time: 156.0   landing_coord: (-0.3679, 0.0432)  epsilon: 0.0\n",
      "episode: 538   score: -107.3262   time_steps: 162  landing_ops_time: 136.0   landing_coord: (-0.2254, -0.0131)  epsilon: 0.0\n",
      "episode: 539   score: -248.721   time_steps: 182  landing_ops_time: 144.0   landing_coord: (-1.0009, 0.4008)  epsilon: 0.0\n",
      "episode: 540   score: -188.1544   time_steps: 128  landing_ops_time: 142.6   landing_coord: (1.0062, 1.2031)  epsilon: 0.0\n",
      "episode: 541   score: 236.3556   time_steps: 158  landing_ops_time: 133.9   landing_coord: (0.0491, -0.0007)  epsilon: 0.0\n",
      "episode: 542   score: -51.7196   time_steps: 80  landing_ops_time: 135.7   landing_coord: (0.7321, 0.1026)  epsilon: 0.0\n",
      "episode: 543   score: -1105.9262   time_steps: 394  landing_ops_time: 111.2   landing_coord: (1.0075, 1.094)  epsilon: 0.0\n",
      "episode: 544   score: 46.3655   time_steps: 121  landing_ops_time: 142.1   landing_coord: (-0.0758, -0.0279)  epsilon: 0.0\n",
      "episode: 545   score: -135.6587   time_steps: 90  landing_ops_time: 139.4   landing_coord: (0.8967, 0.0173)  epsilon: 0.0\n",
      "episode: 546   score: -596.2799   time_steps: 325  landing_ops_time: 136.7   landing_coord: (1.0044, 0.8645)  epsilon: 0.0\n",
      "episode: 547   score: -172.2043   time_steps: 141  landing_ops_time: 155.7   landing_coord: (-1.005, -0.096)  epsilon: 0.0\n",
      "episode: 548   score: -4891.7074   time_steps: 1001  landing_ops_time: 158.1   landing_coord: (0.4736, 0.9114)  epsilon: 0.0\n",
      "episode: 549   score: -103.7324   time_steps: 80  landing_ops_time: 242.0   landing_coord: (-0.5895, 0.1261)  epsilon: 0.0\n",
      "episode: 550   score: -15.5661   time_steps: 149  landing_ops_time: 231.8   landing_coord: (-0.6105, -0.0522)  epsilon: 0.0\n",
      "episode: 551   score: -193.6982   time_steps: 231  landing_ops_time: 233.9   landing_coord: (-1.0033, 0.6207)  epsilon: 0.0\n",
      "episode: 552   score: -128.5641   time_steps: 112  landing_ops_time: 241.2   landing_coord: (0.8693, -0.1458)  epsilon: 0.0\n",
      "episode: 553   score: -34.5535   time_steps: 154  landing_ops_time: 244.4   landing_coord: (-0.6656, -0.0695)  epsilon: 0.0\n",
      "episode: 554   score: -116.7051   time_steps: 173  landing_ops_time: 220.4   landing_coord: (-1.0031, 0.5465)  epsilon: 0.0\n",
      "episode: 555   score: -83.3235   time_steps: 71  landing_ops_time: 225.6   landing_coord: (0.6158, -0.0724)  epsilon: 0.0\n",
      "episode: 556   score: -132.5514   time_steps: 163  landing_ops_time: 223.7   landing_coord: (1.0069, 0.6057)  epsilon: 0.0\n",
      "episode: 557   score: -117.3947   time_steps: 180  landing_ops_time: 207.5   landing_coord: (-1.0036, 0.3923)  epsilon: 0.0\n",
      "episode: 558   score: -4794.3952   time_steps: 1001  landing_ops_time: 211.4   landing_coord: (-0.4505, 1.1375)  epsilon: 0.0\n",
      "episode: 559   score: -824.3674   time_steps: 430  landing_ops_time: 211.4   landing_coord: (-0.2939, 0.0075)  epsilon: 0.0\n",
      "episode: 560   score: -42.4724   time_steps: 66  landing_ops_time: 246.4   landing_coord: (-0.4239, 0.1105)  epsilon: 0.0\n",
      "episode: 561   score: -532.5565   time_steps: 334  landing_ops_time: 238.1   landing_coord: (1.0006, 0.6508)  epsilon: 0.0\n",
      "episode: 562   score: -144.4554   time_steps: 119  landing_ops_time: 248.4   landing_coord: (1.0094, 0.7523)  epsilon: 0.0\n",
      "episode: 563   score: -136.4421   time_steps: 145  landing_ops_time: 249.1   landing_coord: (1.003, 0.2684)  epsilon: 0.0\n",
      "episode: 564   score: 13.12   time_steps: 87  landing_ops_time: 248.2   landing_coord: (0.2305, -0.0512)  epsilon: 0.0\n",
      "episode: 565   score: -705.7065   time_steps: 362  landing_ops_time: 239.6   landing_coord: (-1.0001, 0.7616)  epsilon: 0.0\n",
      "episode: 566   score: 9.5413   time_steps: 81  landing_ops_time: 268.7   landing_coord: (0.2739, -0.0437)  epsilon: 0.0\n",
      "episode: 567   score: -3118.8063   time_steps: 725  landing_ops_time: 260.5   landing_coord: (0.5008, -0.0972)  epsilon: 0.0\n",
      "episode: 568   score: -175.4046   time_steps: 136  landing_ops_time: 315.0   landing_coord: (-0.4079, 0.1448)  epsilon: 0.0\n",
      "episode: 569   score: -110.001   time_steps: 115  landing_ops_time: 228.5   landing_coord: (1.007, 0.3364)  epsilon: 0.0\n",
      "episode: 570   score: -858.3231   time_steps: 424  landing_ops_time: 197.0   landing_coord: (0.5891, -0.1838)  epsilon: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 571   score: 59.2315   time_steps: 75  landing_ops_time: 232.8   landing_coord: (-0.0218, -0.0374)  epsilon: 0.0\n",
      "episode: 572   score: -43.6833   time_steps: 92  landing_ops_time: 206.9   landing_coord: (-0.338, 0.0031)  epsilon: 0.0\n",
      "episode: 573   score: -103.8896   time_steps: 172  landing_ops_time: 204.2   landing_coord: (1.0025, 0.455)  epsilon: 0.0\n",
      "episode: 574   score: -203.2241   time_steps: 112  landing_ops_time: 206.9   landing_coord: (1.0045, 0.3623)  epsilon: 0.0\n",
      "episode: 575   score: -2964.3147   time_steps: 745  landing_ops_time: 209.4   landing_coord: (0.2619, 0.0237)  epsilon: 0.0\n",
      "episode: 576   score: -119.6929   time_steps: 166  landing_ops_time: 247.7   landing_coord: (1.0052, 0.7363)  epsilon: 0.0\n",
      "episode: 577   score: -141.6191   time_steps: 264  landing_ops_time: 256.2   landing_coord: (1.0024, 0.694)  epsilon: 0.0\n",
      "episode: 578   score: -36.5917   time_steps: 143  landing_ops_time: 210.1   landing_coord: (-0.1396, -0.039)  epsilon: 0.0\n",
      "episode: 579   score: 0.2822   time_steps: 81  landing_ops_time: 210.8   landing_coord: (0.2597, 0.0179)  epsilon: 0.0\n",
      "episode: 580   score: -32.6842   time_steps: 125  landing_ops_time: 207.4   landing_coord: (0.554, 0.1691)  epsilon: 0.0\n",
      "episode: 581   score: -1684.5383   time_steps: 572  landing_ops_time: 177.5   landing_coord: (0.0933, -0.0012)  epsilon: 0.0\n",
      "episode: 582   score: 11.388   time_steps: 76  landing_ops_time: 227.2   landing_coord: (0.2266, -0.0314)  epsilon: 0.0\n",
      "episode: 583   score: -33.2756   time_steps: 152  landing_ops_time: 225.6   landing_coord: (0.5495, -0.0593)  epsilon: 0.0\n",
      "episode: 584   score: -762.8941   time_steps: 362  landing_ops_time: 223.6   landing_coord: (1.0068, 1.0046)  epsilon: 0.0\n",
      "episode: 585   score: -128.8514   time_steps: 80  landing_ops_time: 248.6   landing_coord: (0.7158, -0.1161)  epsilon: 0.0\n",
      "episode: 586   score: 150.4609   time_steps: 284  landing_ops_time: 182.1   landing_coord: (-0.1152, -0.001)  epsilon: 0.0\n",
      "episode: 587   score: -463.3486   time_steps: 336  landing_ops_time: 193.9   landing_coord: (0.3288, -0.0741)  epsilon: 0.0\n",
      "episode: 588   score: -59.1456   time_steps: 60  landing_ops_time: 201.1   landing_coord: (0.4983, 0.0946)  epsilon: 0.0\n",
      "episode: 589   score: -105.0621   time_steps: 121  landing_ops_time: 192.8   landing_coord: (1.0036, 0.5138)  epsilon: 0.0\n",
      "episode: 590   score: -59.7017   time_steps: 189  landing_ops_time: 196.8   landing_coord: (0.7091, 0.0919)  epsilon: 0.0\n",
      "episode: 591   score: -242.3239   time_steps: 251  landing_ops_time: 203.2   landing_coord: (1.0028, 0.8602)  epsilon: 0.0\n",
      "episode: 592   score: -263.1167   time_steps: 283  landing_ops_time: 171.1   landing_coord: (0.4545, -0.1495)  epsilon: 0.0\n",
      "episode: 593   score: -119.3488   time_steps: 155  landing_ops_time: 191.8   landing_coord: (1.0001, 0.7521)  epsilon: 0.0\n",
      "episode: 594   score: -81.1989   time_steps: 134  landing_ops_time: 192.1   landing_coord: (0.7039, -0.0639)  epsilon: 0.0\n",
      "episode: 595   score: -440.5972   time_steps: 148  landing_ops_time: 169.3   landing_coord: (-1.0092, 1.502)  epsilon: 0.0\n",
      "episode: 596   score: -116.0218   time_steps: 217  landing_ops_time: 176.1   landing_coord: (0.6305, -0.1427)  epsilon: 0.0\n",
      "episode: 597   score: 152.807   time_steps: 215  landing_ops_time: 169.4   landing_coord: (0.0944, -0.0009)  epsilon: 0.0\n",
      "episode: 598   score: -92.815   time_steps: 177  landing_ops_time: 157.3   landing_coord: (-0.6524, -0.0763)  epsilon: 0.0\n",
      "episode: 599   score: -54.1828   time_steps: 84  landing_ops_time: 169.0   landing_coord: (0.6128, -0.0755)  epsilon: 0.0\n",
      "episode: 600   score: -139.7454   time_steps: 84  landing_ops_time: 165.3   landing_coord: (-0.7568, -0.1845)  epsilon: 0.0\n",
      "episode: 601   score: -147.9194   time_steps: 86  landing_ops_time: 154.8   landing_coord: (-0.703, -0.3255)  epsilon: 0.0\n",
      "episode: 602   score: -225.8284   time_steps: 252  landing_ops_time: 138.3   landing_coord: (0.7839, -0.0014)  epsilon: 0.0\n",
      "episode: 603   score: -176.3186   time_steps: 319  landing_ops_time: 135.2   landing_coord: (-0.45, -0.1078)  epsilon: 0.0\n",
      "episode: 604   score: -487.9043   time_steps: 306  landing_ops_time: 151.6   landing_coord: (1.0026, 0.6477)  epsilon: 0.0\n",
      "episode: 605   score: 186.9543   time_steps: 209  landing_ops_time: 168.8   landing_coord: (0.1823, -0.0069)  epsilon: 0.0\n",
      "episode: 606   score: -258.9543   time_steps: 260  landing_ops_time: 174.9   landing_coord: (0.7518, 0.2025)  epsilon: 0.0\n",
      "episode: 607   score: -52.7353   time_steps: 67  landing_ops_time: 179.2   landing_coord: (0.4443, 0.176)  epsilon: 0.0\n",
      "episode: 608   score: -1720.6119   time_steps: 562  landing_ops_time: 164.4   landing_coord: (0.0664, -0.0008)  epsilon: 0.0\n",
      "episode: 609   score: -153.5402   time_steps: 68  landing_ops_time: 202.9   landing_coord: (-0.5496, -0.265)  epsilon: 0.0\n",
      "episode: 610   score: -114.1684   time_steps: 127  landing_ops_time: 201.3   landing_coord: (1.0082, 0.2427)  epsilon: 0.0\n",
      "episode: 611   score: -440.8096   time_steps: 336  landing_ops_time: 205.6   landing_coord: (-0.763, 0.0311)  epsilon: 0.0\n",
      "episode: 612   score: -79.9204   time_steps: 78  landing_ops_time: 230.6   landing_coord: (-0.3861, 0.0046)  epsilon: 0.0\n",
      "episode: 613   score: -17.9273   time_steps: 93  landing_ops_time: 213.2   landing_coord: (-0.3382, 0.0233)  epsilon: 0.0\n",
      "episode: 614   score: -113.5503   time_steps: 116  landing_ops_time: 190.6   landing_coord: (1.0063, 0.1443)  epsilon: 0.0\n",
      "episode: 615   score: -75.5276   time_steps: 71  landing_ops_time: 171.6   landing_coord: (-0.5872, 0.0026)  epsilon: 0.0\n",
      "episode: 616   score: -323.6965   time_steps: 234  landing_ops_time: 157.8   landing_coord: (1.0003, 1.0835)  epsilon: 0.0\n",
      "episode: 617   score: -194.3356   time_steps: 335  landing_ops_time: 155.2   landing_coord: (0.1546, 0.0051)  epsilon: 0.0\n",
      "episode: 618   score: -570.5222   time_steps: 327  landing_ops_time: 182.0   landing_coord: (0.6715, -0.1244)  epsilon: 0.0\n",
      "episode: 619   score: -563.7285   time_steps: 415  landing_ops_time: 158.5   landing_coord: (0.0379, -0.0011)  epsilon: 0.0\n",
      "episode: 620   score: -1452.8878   time_steps: 513  landing_ops_time: 193.2   landing_coord: (0.4375, -0.0334)  epsilon: 0.0\n",
      "episode: 621   score: -210.3867   time_steps: 200  landing_ops_time: 231.8   landing_coord: (-0.0263, 0.0103)  epsilon: 0.0\n",
      "episode: 622   score: 32.6345   time_steps: 218  landing_ops_time: 218.2   landing_coord: (-0.0489, -0.0353)  epsilon: 0.0\n",
      "episode: 623   score: -1006.0708   time_steps: 407  landing_ops_time: 232.2   landing_coord: (1.0029, -0.0173)  epsilon: 0.0\n",
      "episode: 624   score: -562.5187   time_steps: 424  landing_ops_time: 263.6   landing_coord: (-0.3622, -0.087)  epsilon: 0.0\n",
      "episode: 625   score: -1124.77   time_steps: 506  landing_ops_time: 294.4   landing_coord: (0.0304, -0.001)  epsilon: 0.0\n",
      "episode: 626   score: -112.8326   time_steps: 124  landing_ops_time: 337.9   landing_coord: (1.0013, 1.0072)  epsilon: 0.0\n",
      "episode: 627   score: -156.5118   time_steps: 114  landing_ops_time: 326.9   landing_coord: (1.0001, 0.4656)  epsilon: 0.0\n",
      "episode: 628   score: -3746.7344   time_steps: 858  landing_ops_time: 304.8   landing_coord: (0.1984, -0.0074)  epsilon: 0.0\n",
      "episode: 629   score: 4.9131   time_steps: 79  landing_ops_time: 357.9   landing_coord: (-0.3889, 0.0188)  epsilon: 0.0\n",
      "episode: 630   score: -3709.2863   time_steps: 1001  landing_ops_time: 324.3   landing_coord: (0.2687, 0.017)  epsilon: 0.0\n",
      "episode: 631   score: -76.6809   time_steps: 196  landing_ops_time: 373.1   landing_coord: (-1.0014, 0.7603)  epsilon: 0.0\n",
      "episode: 632   score: -1780.5759   time_steps: 562  landing_ops_time: 372.7   landing_coord: (-1.0005, 0.5959)  epsilon: 0.0\n",
      "episode: 633   score: -861.3125   time_steps: 433  landing_ops_time: 407.1   landing_coord: (-1.0007, 0.6997)  epsilon: 0.0\n",
      "episode: 634   score: -107.5729   time_steps: 206  landing_ops_time: 409.7   landing_coord: (1.001, 0.8113)  epsilon: 0.0\n",
      "episode: 635   score: -4457.978   time_steps: 1001  landing_ops_time: 387.9   landing_coord: (-0.3817, 0.7361)  epsilon: 0.0\n",
      "episode: 636   score: 2.5535   time_steps: 77  landing_ops_time: 437.4   landing_coord: (-0.3021, -0.0323)  epsilon: 0.0\n",
      "episode: 637   score: -79.5028   time_steps: 77  landing_ops_time: 432.7   landing_coord: (-0.4697, 0.0025)  epsilon: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 638   score: -39.6799   time_steps: 82  landing_ops_time: 429.0   landing_coord: (0.5129, -0.0049)  epsilon: 0.0\n",
      "episode: 639   score: -50.2254   time_steps: 142  landing_ops_time: 351.4   landing_coord: (-0.552, 0.1972)  epsilon: 0.0\n",
      "episode: 640   score: -142.7486   time_steps: 75  landing_ops_time: 357.7   landing_coord: (-0.7522, -0.1441)  epsilon: 0.0\n",
      "episode: 641   score: -663.0469   time_steps: 426  landing_ops_time: 265.1   landing_coord: (-0.4324, -0.0548)  epsilon: 0.0\n",
      "episode: 642   score: -139.9019   time_steps: 161  landing_ops_time: 288.1   landing_coord: (1.0025, 0.6454)  epsilon: 0.0\n",
      "episode: 643   score: -103.8625   time_steps: 101  landing_ops_time: 248.0   landing_coord: (0.8179, 0.125)  epsilon: 0.0\n",
      "episode: 644   score: -1412.7339   time_steps: 517  landing_ops_time: 214.8   landing_coord: (0.2092, 0.0231)  epsilon: 0.0\n",
      "episode: 645   score: -826.7647   time_steps: 439  landing_ops_time: 245.9   landing_coord: (0.4812, -0.1249)  epsilon: 0.0\n",
      "episode: 646   score: -1259.0297   time_steps: 446  landing_ops_time: 189.7   landing_coord: (-1.0063, -0.2392)  epsilon: 0.0\n",
      "episode: 647   score: -1710.0385   time_steps: 573  landing_ops_time: 226.6   landing_coord: (0.5054, -0.0467)  epsilon: 0.0\n",
      "episode: 648   score: -755.2355   time_steps: 371  landing_ops_time: 276.2   landing_coord: (-1.001, 0.1055)  epsilon: 0.0\n",
      "episode: 649   score: -67.5616   time_steps: 335  landing_ops_time: 305.1   landing_coord: (-0.6757, 0.1311)  epsilon: 0.0\n",
      "episode: 650   score: 266.1842   time_steps: 230  landing_ops_time: 324.4   landing_coord: (-0.0449, -0.0014)  epsilon: 0.0\n",
      "episode: 651   score: -1708.3478   time_steps: 552  landing_ops_time: 339.9   landing_coord: (0.8618, -0.2129)  epsilon: 0.0\n",
      "episode: 652   score: 58.6321   time_steps: 80  landing_ops_time: 352.5   landing_coord: (0.0509, -0.0346)  epsilon: 0.0\n",
      "episode: 653   score: -103.993   time_steps: 95  landing_ops_time: 344.4   landing_coord: (-0.7763, -0.1405)  epsilon: 0.0\n",
      "episode: 654   score: -65.974   time_steps: 260  landing_ops_time: 343.8   landing_coord: (-0.2296, -0.0566)  epsilon: 0.0\n",
      "episode: 655   score: -173.5724   time_steps: 156  landing_ops_time: 318.1   landing_coord: (1.0005, 0.9869)  epsilon: 0.0\n",
      "episode: 656   score: -149.8011   time_steps: 79  landing_ops_time: 289.8   landing_coord: (-0.6526, -0.2697)  epsilon: 0.0\n",
      "episode: 657   score: -1096.4311   time_steps: 421  landing_ops_time: 253.1   landing_coord: (1.0003, 0.6936)  epsilon: 0.0\n",
      "episode: 658   score: -1032.4319   time_steps: 429  landing_ops_time: 237.9   landing_coord: (-0.678, -0.1756)  epsilon: 0.0\n",
      "episode: 659   score: -183.9243   time_steps: 98  landing_ops_time: 243.7   landing_coord: (1.0161, -0.0049)  epsilon: 0.0\n",
      "episode: 660   score: -2301.9425   time_steps: 610  landing_ops_time: 220.0   landing_coord: (-1.0027, -0.1544)  epsilon: 0.0\n",
      "episode: 661   score: -112.5224   time_steps: 85  landing_ops_time: 258.0   landing_coord: (0.8198, -0.0879)  epsilon: 0.0\n",
      "episode: 662   score: 108.7462   time_steps: 276  landing_ops_time: 211.3   landing_coord: (-0.6331, -0.0976)  epsilon: 0.0\n",
      "episode: 663   score: -1728.1889   time_steps: 543  landing_ops_time: 230.9   landing_coord: (-0.224, -0.0495)  epsilon: 0.0\n",
      "episode: 664   score: -151.7836   time_steps: 262  landing_ops_time: 275.7   landing_coord: (1.0, 0.7185)  epsilon: 0.0\n",
      "episode: 665   score: 251.4442   time_steps: 243  landing_ops_time: 275.9   landing_coord: (-0.1018, -0.0007)  epsilon: 0.0\n",
      "episode: 666   score: 14.9706   time_steps: 153  landing_ops_time: 284.6   landing_coord: (-0.3726, 0.0448)  epsilon: 0.0\n",
      "episode: 667   score: -614.3471   time_steps: 429  landing_ops_time: 292.0   landing_coord: (-0.3321, -0.0223)  epsilon: 0.0\n",
      "episode: 668   score: -223.5262   time_steps: 85  landing_ops_time: 292.8   landing_coord: (-0.8728, -0.1786)  epsilon: 0.0\n",
      "episode: 669   score: -417.6622   time_steps: 324  landing_ops_time: 258.4   landing_coord: (1.0025, 0.6519)  epsilon: 0.0\n",
      "episode: 670   score: -95.8254   time_steps: 102  landing_ops_time: 281.0   landing_coord: (-0.406, -0.0069)  epsilon: 0.0\n",
      "episode: 671   score: -23.7921   time_steps: 62  landing_ops_time: 230.2   landing_coord: (-0.3181, 0.0765)  epsilon: 0.0\n",
      "episode: 672   score: -497.6765   time_steps: 341  landing_ops_time: 227.9   landing_coord: (-0.2915, -0.0926)  epsilon: 0.0\n",
      "episode: 673   score: -1235.003   time_steps: 428  landing_ops_time: 234.4   landing_coord: (-1.0053, 0.3505)  epsilon: 0.0\n",
      "episode: 674   score: 236.6186   time_steps: 190  landing_ops_time: 222.9   landing_coord: (0.2229, 0.0121)  epsilon: 0.0\n",
      "episode: 675   score: -74.4018   time_steps: 72  landing_ops_time: 215.7   landing_coord: (-0.3608, -0.1331)  epsilon: 0.0\n",
      "episode: 676   score: -176.5586   time_steps: 211  landing_ops_time: 198.6   landing_coord: (1.0027, 1.0777)  epsilon: 0.0\n",
      "episode: 677   score: -1005.7829   time_steps: 454  landing_ops_time: 204.4   landing_coord: (-0.6544, 0.1424)  epsilon: 0.0\n",
      "episode: 678   score: -112.2675   time_steps: 62  landing_ops_time: 206.9   landing_coord: (-0.4838, 0.0688)  epsilon: 0.0\n",
      "episode: 679   score: -126.8035   time_steps: 110  landing_ops_time: 204.6   landing_coord: (1.0028, 0.2468)  epsilon: 0.0\n",
      "episode: 680   score: -1329.7637   time_steps: 438  landing_ops_time: 183.2   landing_coord: (-0.778, -0.1061)  epsilon: 0.0\n",
      "episode: 681   score: -171.2786   time_steps: 134  landing_ops_time: 216.8   landing_coord: (1.0044, 1.1114)  epsilon: 0.0\n",
      "episode: 682   score: -146.6492   time_steps: 99  landing_ops_time: 224.0   landing_coord: (1.0081, 0.1546)  epsilon: 0.0\n",
      "episode: 683   score: -2161.765   time_steps: 584  landing_ops_time: 199.8   landing_coord: (-0.6012, 0.2227)  epsilon: 0.0\n",
      "episode: 684   score: -59.1187   time_steps: 204  landing_ops_time: 215.4   landing_coord: (0.5289, -0.0011)  epsilon: 0.0\n",
      "episode: 685   score: -190.1494   time_steps: 119  landing_ops_time: 216.8   landing_coord: (1.0038, 0.9154)  epsilon: 0.0\n",
      "episode: 686   score: -3154.4772   time_steps: 730  landing_ops_time: 221.5   landing_coord: (0.2769, -0.0318)  epsilon: 0.0\n",
      "episode: 687   score: -87.972   time_steps: 78  landing_ops_time: 273.4   landing_coord: (0.7599, 0.1428)  epsilon: 0.0\n",
      "episode: 688   score: -160.2327   time_steps: 106  landing_ops_time: 235.8   landing_coord: (1.0125, 0.5407)  epsilon: 0.0\n",
      "episode: 689   score: -190.5701   time_steps: 120  landing_ops_time: 240.2   landing_coord: (1.0039, 1.2815)  epsilon: 0.0\n",
      "episode: 690   score: -846.491   time_steps: 444  landing_ops_time: 241.2   landing_coord: (0.2192, -0.0164)  epsilon: 0.0\n",
      "episode: 691   score: -200.5648   time_steps: 196  landing_ops_time: 241.8   landing_coord: (1.0011, 1.0957)  epsilon: 0.0\n",
      "episode: 692   score: -149.4591   time_steps: 99  landing_ops_time: 248.0   landing_coord: (1.0013, 0.6667)  epsilon: 0.0\n",
      "episode: 693   score: -188.4224   time_steps: 106  landing_ops_time: 248.0   landing_coord: (1.0133, 1.0254)  epsilon: 0.0\n",
      "episode: 694   score: -53.0824   time_steps: 148  landing_ops_time: 200.2   landing_coord: (-0.4295, 0.0207)  epsilon: 0.0\n",
      "episode: 695   score: -173.5491   time_steps: 151  landing_ops_time: 194.6   landing_coord: (1.0022, 1.0077)  epsilon: 0.0\n",
      "episode: 696   score: 11.7605   time_steps: 181  landing_ops_time: 197.8   landing_coord: (0.0985, -0.0307)  epsilon: 0.0\n",
      "episode: 697   score: -1817.1231   time_steps: 501  landing_ops_time: 142.9   landing_coord: (1.0029, 1.2262)  epsilon: 0.0\n",
      "episode: 698   score: -12.024   time_steps: 66  landing_ops_time: 185.2   landing_coord: (0.3802, 0.1061)  epsilon: 0.0\n",
      "episode: 699   score: -164.4545   time_steps: 112  landing_ops_time: 181.2   landing_coord: (1.0074, 0.5718)  epsilon: 0.0\n",
      "episode: 700   score: -153.3974   time_steps: 110  landing_ops_time: 180.4   landing_coord: (1.0004, 0.4084)  epsilon: 0.0\n",
      "episode: 701   score: -220.568   time_steps: 195  landing_ops_time: 147.0   landing_coord: (-0.9914, 0.0336)  epsilon: 0.0\n",
      "episode: 702   score: -95.8183   time_steps: 305  landing_ops_time: 146.9   landing_coord: (-0.2035, 0.0034)  epsilon: 0.0\n",
      "episode: 703   score: -409.9532   time_steps: 242  landing_ops_time: 167.5   landing_coord: (1.0068, 0.6488)  epsilon: 0.0\n",
      "episode: 704   score: -383.0616   time_steps: 270  landing_ops_time: 181.1   landing_coord: (1.0064, 0.7508)  epsilon: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 705   score: -255.4014   time_steps: 81  landing_ops_time: 193.3   landing_coord: (0.7467, -0.0199)  epsilon: 0.0\n",
      "episode: 706   score: -229.2969   time_steps: 84  landing_ops_time: 186.3   landing_coord: (1.0125, -0.1723)  epsilon: 0.0\n",
      "episode: 707   score: -716.6625   time_steps: 347  landing_ops_time: 176.6   landing_coord: (1.003, 1.1592)  epsilon: 0.0\n",
      "episode: 708   score: -383.5306   time_steps: 96  landing_ops_time: 161.2   landing_coord: (-1.002, 0.3044)  epsilon: 0.0\n",
      "episode: 709   score: -131.3661   time_steps: 65  landing_ops_time: 164.2   landing_coord: (0.6159, 0.1472)  epsilon: 0.0\n",
      "episode: 710   score: -217.5995   time_steps: 173  landing_ops_time: 159.5   landing_coord: (1.0015, 1.4343)  epsilon: 0.0\n",
      "episode: 711   score: -428.5613   time_steps: 296  landing_ops_time: 165.8   landing_coord: (1.0022, 0.8997)  epsilon: 0.0\n",
      "episode: 712   score: -139.2414   time_steps: 104  landing_ops_time: 175.9   landing_coord: (0.9394, -0.1327)  epsilon: 0.0\n",
      "episode: 713   score: -182.2057   time_steps: 162  landing_ops_time: 155.8   landing_coord: (1.0027, 1.1486)  epsilon: 0.0\n",
      "episode: 714   score: -39.88   time_steps: 291  landing_ops_time: 147.8   landing_coord: (-0.0894, -0.0006)  epsilon: 0.0\n",
      "episode: 715   score: -138.017   time_steps: 130  landing_ops_time: 149.9   landing_coord: (-1.0057, 0.3796)  epsilon: 0.0\n",
      "episode: 716   score: 34.415   time_steps: 77  landing_ops_time: 154.8   landing_coord: (0.159, -0.0406)  epsilon: 0.0\n",
      "episode: 717   score: -173.4602   time_steps: 106  landing_ops_time: 154.1   landing_coord: (1.0107, 1.1561)  epsilon: 0.0\n",
      "episode: 718   score: -145.784   time_steps: 102  landing_ops_time: 130.0   landing_coord: (1.0093, 0.5777)  epsilon: 0.0\n",
      "episode: 719   score: -274.3491   time_steps: 83  landing_ops_time: 130.6   landing_coord: (-1.02, 0.5759)  epsilon: 0.0\n",
      "episode: 720   score: -1388.1776   time_steps: 438  landing_ops_time: 132.4   landing_coord: (1.0046, 1.0091)  epsilon: 0.0\n",
      "episode: 721   score: -214.9042   time_steps: 85  landing_ops_time: 158.9   landing_coord: (-1.0104, 0.9407)  epsilon: 0.0\n",
      "episode: 722   score: -149.9487   time_steps: 137  landing_ops_time: 137.8   landing_coord: (1.004, 0.7376)  epsilon: 0.0\n",
      "episode: 723   score: -111.9952   time_steps: 87  landing_ops_time: 141.1   landing_coord: (0.771, 0.1075)  epsilon: 0.0\n",
      "episode: 724   score: -335.4036   time_steps: 207  landing_ops_time: 133.6   landing_coord: (1.0004, 1.0855)  epsilon: 0.0\n",
      "episode: 725   score: -303.1547   time_steps: 180  landing_ops_time: 125.2   landing_coord: (1.0017, 1.4208)  epsilon: 0.0\n",
      "episode: 726   score: 3.4297   time_steps: 105  landing_ops_time: 130.2   landing_coord: (0.2619, -0.0413)  epsilon: 0.0\n",
      "episode: 727   score: -178.611   time_steps: 133  landing_ops_time: 133.0   landing_coord: (-1.0077, 0.4267)  epsilon: 0.0\n",
      "episode: 728   score: -226.2036   time_steps: 158  landing_ops_time: 135.7   landing_coord: (1.0004, 1.422)  epsilon: 0.0\n",
      "episode: 729   score: -230.5031   time_steps: 95  landing_ops_time: 141.3   landing_coord: (-1.0137, 0.6259)  epsilon: 0.0\n",
      "episode: 730   score: -247.4511   time_steps: 351  landing_ops_time: 142.5   landing_coord: (0.4334, 0.0303)  epsilon: 0.0\n",
      "episode: 731   score: -1486.2972   time_steps: 414  landing_ops_time: 133.8   landing_coord: (1.0231, 0.5196)  epsilon: 0.0\n",
      "episode: 732   score: -776.5602   time_steps: 351  landing_ops_time: 166.7   landing_coord: (1.0031, 1.2984)  epsilon: 0.0\n",
      "episode: 733   score: -1558.7311   time_steps: 560  landing_ops_time: 188.1   landing_coord: (-0.0146, -0.0008)  epsilon: 0.0\n",
      "episode: 734   score: -647.7962   time_steps: 435  landing_ops_time: 235.4   landing_coord: (0.1115, -0.0004)  epsilon: 0.0\n",
      "episode: 735   score: -247.6771   time_steps: 112  landing_ops_time: 258.2   landing_coord: (-1.0159, 0.3114)  epsilon: 0.0\n",
      "episode: 736   score: -253.0897   time_steps: 91  landing_ops_time: 251.4   landing_coord: (-1.0035, 0.5286)  epsilon: 0.0\n",
      "episode: 737   score: -170.7344   time_steps: 190  landing_ops_time: 250.0   landing_coord: (-0.4775, -0.1068)  epsilon: 0.0\n",
      "episode: 738   score: -199.4491   time_steps: 122  landing_ops_time: 255.7   landing_coord: (1.0019, 1.3235)  epsilon: 0.0\n",
      "episode: 739   score: -411.0526   time_steps: 87  landing_ops_time: 252.1   landing_coord: (-1.0007, 0.101)  epsilon: 0.0\n",
      "episode: 740   score: -38.1275   time_steps: 64  landing_ops_time: 251.3   landing_coord: (0.3279, 0.0913)  epsilon: 0.0\n",
      "episode: 741   score: -190.6264   time_steps: 103  landing_ops_time: 222.6   landing_coord: (1.0077, 1.1391)  epsilon: 0.0\n",
      "episode: 742   score: 217.4711   time_steps: 215  landing_ops_time: 191.5   landing_coord: (0.0621, -0.0012)  epsilon: 0.0\n",
      "episode: 743   score: -36.6492   time_steps: 119  landing_ops_time: 177.9   landing_coord: (0.3428, -0.093)  epsilon: 0.0\n",
      "episode: 744   score: -217.4859   time_steps: 153  landing_ops_time: 133.8   landing_coord: (1.006, 1.2799)  epsilon: 0.0\n",
      "episode: 745   score: -283.6241   time_steps: 170  landing_ops_time: 105.6   landing_coord: (1.001, 1.3705)  epsilon: 0.0\n",
      "episode: 746   score: -181.5393   time_steps: 117  landing_ops_time: 111.4   landing_coord: (1.0034, 1.2266)  epsilon: 0.0\n",
      "episode: 747   score: -184.3049   time_steps: 113  landing_ops_time: 114.0   landing_coord: (1.0028, 1.3228)  epsilon: 0.0\n",
      "episode: 748   score: -506.6576   time_steps: 291  landing_ops_time: 106.3   landing_coord: (1.0015, 1.198)  epsilon: 0.0\n",
      "episode: 749   score: -267.2306   time_steps: 89  landing_ops_time: 123.2   landing_coord: (-1.0102, 0.1078)  epsilon: 0.0\n",
      "episode: 750   score: -199.5725   time_steps: 116  landing_ops_time: 123.4   landing_coord: (-1.0152, 0.0555)  epsilon: 0.0\n",
      "episode: 751   score: -328.2501   time_steps: 181  landing_ops_time: 128.6   landing_coord: (-0.6722, -0.1582)  epsilon: 0.0\n",
      "episode: 752   score: -158.6676   time_steps: 222  landing_ops_time: 136.4   landing_coord: (-0.5786, 0.1081)  epsilon: 0.0\n",
      "episode: 753   score: -88.1222   time_steps: 92  landing_ops_time: 137.1   landing_coord: (-0.6708, 0.1204)  epsilon: 0.0\n",
      "episode: 754   score: -225.0307   time_steps: 89  landing_ops_time: 134.4   landing_coord: (-1.0063, 0.1871)  epsilon: 0.0\n",
      "episode: 755   score: -408.2332   time_steps: 244  landing_ops_time: 128.0   landing_coord: (1.0022, 0.9184)  epsilon: 0.0\n",
      "episode: 756   score: -179.9734   time_steps: 111  landing_ops_time: 135.4   landing_coord: (1.0097, 1.1307)  epsilon: 0.0\n",
      "episode: 757   score: -50.5296   time_steps: 75  landing_ops_time: 134.8   landing_coord: (-0.355, 0.0181)  epsilon: 0.0\n",
      "episode: 758   score: -238.4049   time_steps: 169  landing_ops_time: 131.0   landing_coord: (1.0032, 1.42)  epsilon: 0.0\n",
      "episode: 759   score: -619.8863   time_steps: 399  landing_ops_time: 118.8   landing_coord: (0.0439, -0.0005)  epsilon: 0.0\n",
      "episode: 760   score: -156.1282   time_steps: 89  landing_ops_time: 149.8   landing_coord: (-1.015, -0.1255)  epsilon: 0.0\n",
      "episode: 761   score: 37.9004   time_steps: 283  landing_ops_time: 147.1   landing_coord: (-0.4463, -0.0527)  epsilon: 0.0\n",
      "episode: 762   score: -215.5137   time_steps: 179  landing_ops_time: 157.3   landing_coord: (1.0019, 1.2484)  epsilon: 0.0\n",
      "episode: 763   score: -35.4232   time_steps: 69  landing_ops_time: 153.0   landing_coord: (0.3718, 0.0544)  epsilon: 0.0\n",
      "episode: 764   score: -79.8756   time_steps: 151  landing_ops_time: 150.7   landing_coord: (-0.3712, 0.1095)  epsilon: 0.0\n",
      "episode: 765   score: -486.7483   time_steps: 361  landing_ops_time: 156.9   landing_coord: (-0.5486, -0.0557)  epsilon: 0.0\n",
      "episode: 766   score: 72.3799   time_steps: 255  landing_ops_time: 168.6   landing_coord: (-0.107, -0.0007)  epsilon: 0.0\n",
      "episode: 767   score: -77.194   time_steps: 70  landing_ops_time: 183.0   landing_coord: (-0.4655, 0.0757)  epsilon: 0.0\n",
      "episode: 768   score: -22.3317   time_steps: 84  landing_ops_time: 182.5   landing_coord: (0.3102, -0.015)  epsilon: 0.0\n",
      "episode: 769   score: -265.054   time_steps: 296  landing_ops_time: 174.0   landing_coord: (-0.5829, 0.0349)  epsilon: 0.0\n",
      "episode: 770   score: 275.3016   time_steps: 163  landing_ops_time: 163.7   landing_coord: (0.0265, -0.0007)  epsilon: 0.0\n",
      "episode: 771   score: -195.1371   time_steps: 107  landing_ops_time: 171.1   landing_coord: (1.007, 0.8939)  epsilon: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 772   score: -22.6396   time_steps: 110  landing_ops_time: 153.5   landing_coord: (-0.3462, 0.085)  epsilon: 0.0\n",
      "episode: 773   score: -221.3758   time_steps: 88  landing_ops_time: 146.6   landing_coord: (-1.0034, -0.013)  epsilon: 0.0\n",
      "episode: 774   score: -182.729   time_steps: 99  landing_ops_time: 148.5   landing_coord: (1.0011, 1.1346)  epsilon: 0.0\n",
      "episode: 775   score: 293.8851   time_steps: 134  landing_ops_time: 143.3   landing_coord: (-0.0033, -0.0014)  epsilon: 0.0\n",
      "episode: 776   score: -221.3547   time_steps: 88  landing_ops_time: 120.6   landing_coord: (-1.0031, -0.1604)  epsilon: 0.0\n",
      "episode: 777   score: -395.2843   time_steps: 198  landing_ops_time: 103.9   landing_coord: (-0.5376, -0.0919)  epsilon: 0.0\n",
      "episode: 778   score: -593.8922   time_steps: 325  landing_ops_time: 116.7   landing_coord: (1.0007, 1.0364)  epsilon: 0.0\n",
      "episode: 779   score: -1919.7513   time_steps: 573  landing_ops_time: 140.8   landing_coord: (-0.3756, -0.0458)  epsilon: 0.0\n",
      "episode: 780   score: -180.6059   time_steps: 142  landing_ops_time: 168.5   landing_coord: (1.007, 0.9389)  epsilon: 0.0\n",
      "episode: 781   score: -198.6759   time_steps: 129  landing_ops_time: 166.4   landing_coord: (1.0117, 0.8671)  epsilon: 0.0\n",
      "episode: 782   score: -142.744   time_steps: 214  landing_ops_time: 168.6   landing_coord: (0.5368, -0.0421)  epsilon: 0.0\n",
      "episode: 783   score: -153.8064   time_steps: 195  landing_ops_time: 179.0   landing_coord: (-0.532, 0.1536)  epsilon: 0.0\n",
      "episode: 784   score: -2273.8277   time_steps: 630  landing_ops_time: 189.7   landing_coord: (-0.4754, 0.1452)  epsilon: 0.0\n",
      "episode: 785   score: -130.2367   time_steps: 96  landing_ops_time: 242.8   landing_coord: (-0.7858, -0.0379)  epsilon: 0.0\n",
      "episode: 786   score: -167.7224   time_steps: 126  landing_ops_time: 239.0   landing_coord: (1.009, 0.9019)  epsilon: 0.0\n",
      "episode: 787   score: -2068.2843   time_steps: 610  landing_ops_time: 242.8   landing_coord: (-0.2899, 0.0171)  epsilon: 0.0\n",
      "episode: 788   score: -2297.2679   time_steps: 620  landing_ops_time: 284.0   landing_coord: (-0.3107, -0.073)  epsilon: 0.0\n",
      "episode: 789   score: -37.2324   time_steps: 345  landing_ops_time: 313.5   landing_coord: (0.0971, -0.0012)  epsilon: 0.0\n",
      "episode: 790   score: -2291.7807   time_steps: 665  landing_ops_time: 290.7   landing_coord: (-0.278, 0.0154)  epsilon: 0.0\n",
      "episode: 791   score: -146.94   time_steps: 125  landing_ops_time: 343.0   landing_coord: (1.0045, 0.2158)  epsilon: 0.0\n",
      "episode: 792   score: -38.186   time_steps: 194  landing_ops_time: 342.6   landing_coord: (0.4896, 0.0337)  epsilon: 0.0\n",
      "episode: 793   score: -834.1929   time_steps: 459  landing_ops_time: 340.6   landing_coord: (-0.5091, 0.1138)  epsilon: 0.0\n",
      "episode: 794   score: -135.2676   time_steps: 143  landing_ops_time: 367.0   landing_coord: (1.0029, -0.0462)  epsilon: 0.0\n",
      "episode: 795   score: -148.3526   time_steps: 111  landing_ops_time: 318.3   landing_coord: (1.0093, 0.532)  epsilon: 0.0\n",
      "episode: 796   score: -72.1435   time_steps: 71  landing_ops_time: 319.8   landing_coord: (0.5035, 0.1152)  epsilon: 0.0\n",
      "episode: 797   score: 266.3484   time_steps: 229  landing_ops_time: 314.3   landing_coord: (-0.0403, -0.0008)  epsilon: 0.0\n",
      "episode: 798   score: 28.569   time_steps: 96  landing_ops_time: 276.2   landing_coord: (0.1885, -0.0308)  epsilon: 0.0\n",
      "episode: 799   score: -62.716   time_steps: 113  landing_ops_time: 223.8   landing_coord: (-0.9465, 0.3187)  epsilon: 0.0\n",
      "episode: 800   score: -71.8942   time_steps: 76  landing_ops_time: 200.6   landing_coord: (0.5144, 0.0936)  epsilon: 0.0\n",
      "episode: 801   score: -142.5782   time_steps: 208  landing_ops_time: 141.7   landing_coord: (-0.4093, -0.1284)  epsilon: 0.0\n",
      "episode: 802   score: 17.6787   time_steps: 266  landing_ops_time: 150.0   landing_coord: (0.5884, -0.091)  epsilon: 0.0\n",
      "episode: 803   score: -161.7682   time_steps: 198  landing_ops_time: 157.2   landing_coord: (0.3945, -0.0303)  epsilon: 0.0\n",
      "episode: 804   score: -167.067   time_steps: 206  landing_ops_time: 131.1   landing_coord: (-0.5888, 0.0095)  epsilon: 0.0\n",
      "episode: 805   score: -213.5227   time_steps: 229  landing_ops_time: 137.4   landing_coord: (-0.3123, -0.0756)  epsilon: 0.0\n",
      "episode: 806   score: 220.7115   time_steps: 174  landing_ops_time: 149.2   landing_coord: (0.1197, -0.001)  epsilon: 0.0\n",
      "episode: 807   score: 224.7289   time_steps: 186  landing_ops_time: 159.5   landing_coord: (-0.053, -0.0012)  epsilon: 0.0\n",
      "episode: 808   score: -72.7507   time_steps: 112  landing_ops_time: 155.2   landing_coord: (-0.6232, -0.1094)  epsilon: 0.0\n",
      "episode: 809   score: 47.3564   time_steps: 75  landing_ops_time: 156.8   landing_coord: (0.0952, -0.0387)  epsilon: 0.0\n",
      "episode: 810   score: -21.2466   time_steps: 85  landing_ops_time: 153.0   landing_coord: (0.4843, -0.0664)  epsilon: 0.0\n",
      "episode: 811   score: -78.9116   time_steps: 88  landing_ops_time: 153.9   landing_coord: (-0.6441, 0.0705)  epsilon: 0.0\n",
      "episode: 812   score: -59.0371   time_steps: 59  landing_ops_time: 141.9   landing_coord: (0.3971, 0.1267)  epsilon: 0.0\n",
      "episode: 813   score: -84.304   time_steps: 85  landing_ops_time: 121.2   landing_coord: (-0.526, -0.2066)  epsilon: 0.0\n",
      "episode: 814   score: -433.1892   time_steps: 244  landing_ops_time: 109.9   landing_coord: (-0.7103, 0.0599)  epsilon: 0.0\n",
      "episode: 815   score: -33.0584   time_steps: 279  landing_ops_time: 113.7   landing_coord: (-0.0983, -0.0012)  epsilon: 0.0\n",
      "episode: 816   score: -179.3218   time_steps: 127  landing_ops_time: 118.7   landing_coord: (-1.0011, 0.8712)  epsilon: 0.0\n",
      "episode: 817   score: -24.3926   time_steps: 84  landing_ops_time: 114.0   landing_coord: (0.3434, -0.0132)  epsilon: 0.0\n",
      "episode: 818   score: -791.3256   time_steps: 403  landing_ops_time: 103.8   landing_coord: (-0.3184, -0.0115)  epsilon: 0.0\n",
      "episode: 819   score: 86.0694   time_steps: 235  landing_ops_time: 132.9   landing_coord: (-0.0906, -0.0014)  epsilon: 0.0\n",
      "episode: 820   score: -376.2339   time_steps: 239  landing_ops_time: 148.9   landing_coord: (-0.5116, -0.1623)  epsilon: 0.0\n",
      "episode: 821   score: -132.2627   time_steps: 68  landing_ops_time: 164.3   landing_coord: (0.5781, -0.0585)  epsilon: 0.0\n",
      "episode: 822   score: 168.6279   time_steps: 277  landing_ops_time: 162.3   landing_coord: (0.4445, -0.019)  epsilon: 0.0\n",
      "episode: 823   score: 170.6591   time_steps: 271  landing_ops_time: 184.1   landing_coord: (-0.4445, -0.0925)  epsilon: 0.0\n",
      "episode: 824   score: -221.6261   time_steps: 199  landing_ops_time: 202.7   landing_coord: (-0.817, 0.1494)  epsilon: 0.0\n",
      "episode: 825   score: -248.3735   time_steps: 247  landing_ops_time: 198.2   landing_coord: (-0.5398, -0.0125)  epsilon: 0.0\n",
      "episode: 826   score: -68.5467   time_steps: 309  landing_ops_time: 195.0   landing_coord: (-0.5846, 0.0864)  epsilon: 0.0\n",
      "episode: 827   score: 60.634   time_steps: 293  landing_ops_time: 213.2   landing_coord: (0.1113, -0.0013)  epsilon: 0.0\n",
      "episode: 828   score: -15.6046   time_steps: 211  landing_ops_time: 234.1   landing_coord: (-0.4331, 0.0321)  epsilon: 0.0\n",
      "episode: 829   score: -133.7416   time_steps: 101  landing_ops_time: 214.9   landing_coord: (0.9169, -0.0617)  epsilon: 0.0\n",
      "episode: 830   score: -165.2488   time_steps: 114  landing_ops_time: 201.5   landing_coord: (1.0074, 0.3274)  epsilon: 0.0\n",
      "episode: 831   score: -283.2755   time_steps: 241  landing_ops_time: 189.0   landing_coord: (-0.5333, 0.012)  epsilon: 0.0\n",
      "episode: 832   score: -192.4669   time_steps: 105  landing_ops_time: 206.3   landing_coord: (1.0076, 0.1376)  epsilon: 0.0\n",
      "episode: 833   score: -122.0988   time_steps: 220  landing_ops_time: 189.1   landing_coord: (-0.2599, -0.0794)  epsilon: 0.0\n",
      "episode: 834   score: -189.0255   time_steps: 126  landing_ops_time: 184.0   landing_coord: (1.003, 0.9697)  epsilon: 0.0\n",
      "episode: 835   score: -1218.1531   time_steps: 500  landing_ops_time: 176.7   landing_coord: (-0.0902, -0.0011)  epsilon: 0.0\n",
      "episode: 836   score: -811.0091   time_steps: 432  landing_ops_time: 202.0   landing_coord: (-0.0877, -0.0005)  epsilon: 0.0\n",
      "episode: 837   score: -55.0672   time_steps: 117  landing_ops_time: 214.3   landing_coord: (-0.8657, -0.1439)  epsilon: 0.0\n",
      "episode: 838   score: -500.4334   time_steps: 436  landing_ops_time: 196.7   landing_coord: (0.0953, -0.0013)  epsilon: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 839   score: -228.9394   time_steps: 90  landing_ops_time: 219.2   landing_coord: (1.0072, 0.4689)  epsilon: 0.0\n",
      "episode: 840   score: -257.9387   time_steps: 199  landing_ops_time: 218.1   landing_coord: (0.5522, -0.1447)  epsilon: 0.0\n",
      "episode: 841   score: -271.5518   time_steps: 190  landing_ops_time: 226.6   landing_coord: (-0.7282, -0.0676)  epsilon: 0.0\n",
      "episode: 842   score: -24.1381   time_steps: 73  landing_ops_time: 221.5   landing_coord: (0.2312, -0.0533)  epsilon: 0.0\n",
      "episode: 843   score: -137.8609   time_steps: 151  landing_ops_time: 218.3   landing_coord: (1.0049, 0.2608)  epsilon: 0.0\n",
      "episode: 844   score: 155.7516   time_steps: 252  landing_ops_time: 211.4   landing_coord: (0.0848, -0.0009)  epsilon: 0.0\n",
      "episode: 845   score: -140.0695   time_steps: 185  landing_ops_time: 224.0   landing_coord: (0.9908, -0.2572)  epsilon: 0.0\n",
      "episode: 846   score: -352.3984   time_steps: 361  landing_ops_time: 192.5   landing_coord: (-0.0706, -0.0012)  epsilon: 0.0\n",
      "episode: 847   score: -159.8304   time_steps: 99  landing_ops_time: 185.4   landing_coord: (0.6168, -0.0966)  epsilon: 0.0\n",
      "episode: 848   score: -188.6679   time_steps: 102  landing_ops_time: 183.6   landing_coord: (1.0027, 0.1846)  epsilon: 0.0\n",
      "episode: 849   score: -955.471   time_steps: 360  landing_ops_time: 150.2   landing_coord: (0.5408, 0.1669)  epsilon: 0.0\n",
      "episode: 850   score: -202.2778   time_steps: 350  landing_ops_time: 177.2   landing_coord: (-0.4869, -0.1356)  epsilon: 0.0\n",
      "episode: 851   score: -162.8345   time_steps: 141  landing_ops_time: 192.3   landing_coord: (1.0062, 0.4655)  epsilon: 0.0\n",
      "episode: 852   score: -72.8692   time_steps: 265  landing_ops_time: 187.4   landing_coord: (-0.2422, -0.0609)  epsilon: 0.0\n",
      "episode: 853   score: -434.9405   time_steps: 359  landing_ops_time: 206.6   landing_coord: (-0.7197, -0.206)  epsilon: 0.0\n",
      "episode: 854   score: -167.718   time_steps: 99  landing_ops_time: 227.4   landing_coord: (1.002, 0.4577)  epsilon: 0.0\n",
      "episode: 855   score: -149.9361   time_steps: 74  landing_ops_time: 212.1   landing_coord: (0.689, -0.0787)  epsilon: 0.0\n",
      "episode: 856   score: -26.2258   time_steps: 132  landing_ops_time: 201.0   landing_coord: (-0.8619, -0.101)  epsilon: 0.0\n",
      "episode: 857   score: 1.3712   time_steps: 81  landing_ops_time: 178.1   landing_coord: (-0.5782, 0.1738)  epsilon: 0.0\n",
      "episode: 858   score: -97.1047   time_steps: 70  landing_ops_time: 176.3   landing_coord: (-0.6244, 0.0288)  epsilon: 0.0\n",
      "episode: 859   score: -107.4657   time_steps: 188  landing_ops_time: 173.1   landing_coord: (-0.5493, 0.0262)  epsilon: 0.0\n",
      "episode: 860   score: -187.9546   time_steps: 97  landing_ops_time: 155.9   landing_coord: (1.0122, -0.0311)  epsilon: 0.0\n",
      "episode: 861   score: -1540.5557   time_steps: 477  landing_ops_time: 130.6   landing_coord: (0.7523, -0.1793)  epsilon: 0.0\n",
      "episode: 862   score: -164.6082   time_steps: 182  landing_ops_time: 164.2   landing_coord: (1.0017, 0.056)  epsilon: 0.0\n",
      "episode: 863   score: -53.9454   time_steps: 200  landing_ops_time: 155.9   landing_coord: (-0.0549, -0.039)  epsilon: 0.0\n",
      "episode: 864   score: -162.913   time_steps: 80  landing_ops_time: 140.0   landing_coord: (-0.9301, -0.1639)  epsilon: 0.0\n",
      "episode: 865   score: -184.1426   time_steps: 258  landing_ops_time: 138.1   landing_coord: (-0.5312, -0.1482)  epsilon: 0.0\n",
      "episode: 866   score: -107.7601   time_steps: 220  landing_ops_time: 156.5   landing_coord: (-0.4375, -0.1477)  epsilon: 0.0\n",
      "episode: 867   score: -179.3362   time_steps: 94  landing_ops_time: 165.3   landing_coord: (1.0077, 0.2645)  epsilon: 0.0\n",
      "episode: 868   score: -1946.7619   time_steps: 569  landing_ops_time: 166.6   landing_coord: (-0.0343, -0.0427)  epsilon: 0.0\n",
      "episode: 869   score: -187.4263   time_steps: 91  landing_ops_time: 216.5   landing_coord: (1.0087, 0.5046)  epsilon: 0.0\n",
      "episode: 870   score: -765.8861   time_steps: 431  landing_ops_time: 206.8   landing_coord: (-0.1027, -0.0008)  epsilon: 0.0\n",
      "episode: 871   score: 209.5562   time_steps: 201  landing_ops_time: 240.2   landing_coord: (0.3751, -0.0993)  epsilon: 0.0\n",
      "episode: 872   score: -131.0952   time_steps: 98  landing_ops_time: 212.6   landing_coord: (-0.8477, 0.0582)  epsilon: 0.0\n",
      "episode: 873   score: -21.2761   time_steps: 70  landing_ops_time: 204.2   landing_coord: (-0.3413, -0.0182)  epsilon: 0.0\n",
      "episode: 874   score: -142.868   time_steps: 101  landing_ops_time: 191.2   landing_coord: (-1.0119, 0.3589)  epsilon: 0.0\n",
      "episode: 875   score: -1863.9686   time_steps: 587  landing_ops_time: 193.3   landing_coord: (-0.1279, 1e-04)  epsilon: 0.0\n",
      "episode: 876   score: -11.4253   time_steps: 218  landing_ops_time: 226.2   landing_coord: (-0.495, 0.0206)  epsilon: 0.0\n",
      "episode: 877   score: -716.0603   time_steps: 376  landing_ops_time: 226.0   landing_coord: (0.0749, -0.0428)  epsilon: 0.0\n",
      "episode: 878   score: -183.7895   time_steps: 114  landing_ops_time: 254.2   landing_coord: (1.0141, 0.3818)  epsilon: 0.0\n",
      "episode: 879   score: -143.1676   time_steps: 190  landing_ops_time: 208.7   landing_coord: (1.0001, 0.1982)  epsilon: 0.0\n",
      "episode: 880   score: -190.8126   time_steps: 155  landing_ops_time: 218.6   landing_coord: (-1.0003, 0.8696)  epsilon: 0.0\n",
      "episode: 881   score: -398.5999   time_steps: 311  landing_ops_time: 191.0   landing_coord: (1.0014, 0.1844)  epsilon: 0.0\n",
      "episode: 882   score: -117.2678   time_steps: 92  landing_ops_time: 202.0   landing_coord: (0.8826, 0.2328)  epsilon: 0.0\n",
      "episode: 883   score: -135.3817   time_steps: 67  landing_ops_time: 201.4   landing_coord: (-0.5583, 0.0144)  epsilon: 0.0\n",
      "episode: 884   score: 35.2451   time_steps: 77  landing_ops_time: 201.1   landing_coord: (-0.141, -0.0365)  epsilon: 0.0\n",
      "episode: 885   score: -185.4657   time_steps: 114  landing_ops_time: 198.7   landing_coord: (1.0125, 0.429)  epsilon: 0.0\n",
      "episode: 886   score: -164.3031   time_steps: 120  landing_ops_time: 151.4   landing_coord: (-1.0014, 0.7372)  epsilon: 0.0\n",
      "episode: 887   score: -92.2477   time_steps: 76  landing_ops_time: 141.6   landing_coord: (0.6054, -0.0105)  epsilon: 0.0\n",
      "episode: 888   score: -248.2146   time_steps: 135  landing_ops_time: 111.6   landing_coord: (-1.0007, 0.8695)  epsilon: 0.0\n",
      "episode: 889   score: -30.8408   time_steps: 77  landing_ops_time: 113.7   landing_coord: (-0.469, -0.0009)  epsilon: 0.0\n",
      "episode: 890   score: -678.2969   time_steps: 287  landing_ops_time: 102.4   landing_coord: (-1.0178, 0.8957)  epsilon: 0.0\n",
      "episode: 891   score: -146.2271   time_steps: 116  landing_ops_time: 115.6   landing_coord: (-1.004, 0.8124)  epsilon: 0.0\n",
      "episode: 892   score: -123.5207   time_steps: 83  landing_ops_time: 96.1   landing_coord: (0.6242, 0.1008)  epsilon: 0.0\n",
      "episode: 893   score: -90.4838   time_steps: 70  landing_ops_time: 95.2   landing_coord: (0.4689, -0.0155)  epsilon: 0.0\n",
      "episode: 894   score: -384.3597   time_steps: 269  landing_ops_time: 95.5   landing_coord: (0.819, 0.0596)  epsilon: 0.0\n",
      "episode: 895   score: -201.7814   time_steps: 100  landing_ops_time: 114.7   landing_coord: (1.0056, 0.5138)  epsilon: 0.0\n",
      "episode: 896   score: -127.0981   time_steps: 110  landing_ops_time: 113.3   landing_coord: (-1.0063, 0.2548)  epsilon: 0.0\n",
      "episode: 897   score: -204.4108   time_steps: 218  landing_ops_time: 112.3   landing_coord: (-0.4717, -0.1126)  epsilon: 0.0\n",
      "episode: 898   score: -4881.5198   time_steps: 1001  landing_ops_time: 126.5   landing_coord: (-0.1011, 0.0824)  epsilon: 0.0\n",
      "episode: 899   score: -521.3758   time_steps: 354  landing_ops_time: 213.1   landing_coord: (0.2423, -0.031)  epsilon: 0.0\n",
      "episode: 900   score: -224.3737   time_steps: 96  landing_ops_time: 240.8   landing_coord: (1.0147, 0.683)  epsilon: 0.0\n",
      "episode: 901   score: -2252.9762   time_steps: 601  landing_ops_time: 221.7   landing_coord: (0.5009, -0.1062)  epsilon: 0.0\n",
      "episode: 902   score: -1283.7411   time_steps: 470  landing_ops_time: 270.2   landing_coord: (1.0031, 0.3775)  epsilon: 0.0\n",
      "episode: 903   score: -170.6602   time_steps: 93  landing_ops_time: 308.9   landing_coord: (1.0024, -0.1324)  epsilon: 0.0\n",
      "episode: 904   score: -451.6361   time_steps: 359  landing_ops_time: 311.2   landing_coord: (-0.2364, -0.0182)  epsilon: 0.0\n",
      "episode: 905   score: -145.0602   time_steps: 214  landing_ops_time: 320.2   landing_coord: (-0.2534, -0.0171)  epsilon: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 906   score: -135.9998   time_steps: 212  landing_ops_time: 331.6   landing_coord: (-0.2262, -0.0192)  epsilon: 0.0\n",
      "episode: 907   score: -62.9931   time_steps: 81  landing_ops_time: 341.8   landing_coord: (-0.7212, -0.0922)  epsilon: 0.0\n",
      "episode: 908   score: 45.2956   time_steps: 75  landing_ops_time: 328.1   landing_coord: (-0.079, -0.0428)  epsilon: 0.0\n",
      "episode: 909   score: -95.3496   time_steps: 249  landing_ops_time: 235.5   landing_coord: (0.1211, -0.0428)  epsilon: 0.0\n",
      "episode: 910   score: -131.591   time_steps: 141  landing_ops_time: 225.0   landing_coord: (-1.0019, 0.4858)  epsilon: 0.0\n",
      "episode: 911   score: -211.7086   time_steps: 194  landing_ops_time: 229.5   landing_coord: (1.0036, 0.0014)  epsilon: 0.0\n",
      "episode: 912   score: -142.0384   time_steps: 218  landing_ops_time: 188.8   landing_coord: (-0.5669, 0.0302)  epsilon: 0.0\n",
      "episode: 913   score: 29.7254   time_steps: 68  landing_ops_time: 163.6   landing_coord: (-0.0097, -0.0428)  epsilon: 0.0\n",
      "episode: 914   score: -32.7958   time_steps: 210  landing_ops_time: 161.1   landing_coord: (-0.4112, -0.0892)  epsilon: 0.0\n",
      "episode: 915   score: -85.6218   time_steps: 212  landing_ops_time: 146.2   landing_coord: (-0.2009, -0.0198)  epsilon: 0.0\n",
      "episode: 916   score: -262.1641   time_steps: 260  landing_ops_time: 146.0   landing_coord: (0.533, -0.0036)  epsilon: 0.0\n",
      "episode: 917   score: -171.5048   time_steps: 197  landing_ops_time: 150.8   landing_coord: (-0.5798, -0.0212)  epsilon: 0.0\n",
      "episode: 918   score: -129.9777   time_steps: 80  landing_ops_time: 162.4   landing_coord: (-0.8766, 0.0561)  epsilon: 0.0\n",
      "episode: 919   score: -2945.2254   time_steps: 747  landing_ops_time: 162.9   landing_coord: (-0.0311, -0.0011)  epsilon: 0.0\n",
      "episode: 920   score: -117.6877   time_steps: 96  landing_ops_time: 212.7   landing_coord: (0.783, 0.0736)  epsilon: 0.0\n",
      "episode: 921   score: -136.0283   time_steps: 108  landing_ops_time: 208.2   landing_coord: (-1.0098, 0.1323)  epsilon: 0.0\n",
      "episode: 922   score: -380.5562   time_steps: 306  landing_ops_time: 199.6   landing_coord: (1.0046, 0.2207)  epsilon: 0.0\n",
      "episode: 923   score: -215.3404   time_steps: 123  landing_ops_time: 208.4   landing_coord: (1.0021, 0.6115)  epsilon: 0.0\n",
      "episode: 924   score: -199.6105   time_steps: 136  landing_ops_time: 213.9   landing_coord: (1.0003, 0.5869)  epsilon: 0.0\n",
      "episode: 925   score: -454.9263   time_steps: 321  landing_ops_time: 206.5   landing_coord: (1.0038, 0.1038)  epsilon: 0.0\n",
      "episode: 926   score: -88.8868   time_steps: 209  landing_ops_time: 217.4   landing_coord: (-0.0767, -0.0276)  epsilon: 0.0\n",
      "episode: 927   score: -97.3347   time_steps: 207  landing_ops_time: 212.3   landing_coord: (-0.2208, -0.0271)  epsilon: 0.0\n",
      "episode: 928   score: 255.03   time_steps: 165  landing_ops_time: 213.3   landing_coord: (-0.1121, -0.001)  epsilon: 0.0\n",
      "episode: 929   score: -127.7168   time_steps: 222  landing_ops_time: 221.8   landing_coord: (0.4004, 0.0859)  epsilon: 0.0\n",
      "episode: 930   score: -1808.9631   time_steps: 577  landing_ops_time: 169.3   landing_coord: (-0.0737, -0.0008)  epsilon: 0.0\n",
      "episode: 931   score: -53.5295   time_steps: 211  landing_ops_time: 217.4   landing_coord: (-0.1635, -0.0373)  epsilon: 0.0\n",
      "episode: 932   score: -255.6183   time_steps: 208  landing_ops_time: 227.7   landing_coord: (1.0079, 0.5065)  epsilon: 0.0\n",
      "episode: 933   score: 28.1895   time_steps: 63  landing_ops_time: 217.9   landing_coord: (-0.3706, 0.0793)  epsilon: 0.0\n",
      "episode: 934   score: -51.2289   time_steps: 90  landing_ops_time: 211.9   landing_coord: (0.3161, 0.0449)  epsilon: 0.0\n",
      "episode: 935   score: -44.4327   time_steps: 201  landing_ops_time: 207.3   landing_coord: (-0.1059, -0.0428)  epsilon: 0.0\n",
      "episode: 936   score: -141.2148   time_steps: 217  landing_ops_time: 195.3   landing_coord: (0.2567, -0.0099)  epsilon: 0.0\n",
      "episode: 937   score: 29.0043   time_steps: 199  landing_ops_time: 196.1   landing_coord: (-0.2798, -0.0748)  epsilon: 0.0\n",
      "episode: 938   score: -124.3365   time_steps: 121  landing_ops_time: 195.3   landing_coord: (-1.0047, 0.389)  epsilon: 0.0\n",
      "episode: 939   score: -59.4637   time_steps: 69  landing_ops_time: 190.9   landing_coord: (-0.2983, 0.0377)  epsilon: 0.0\n",
      "episode: 940   score: -212.1968   time_steps: 163  landing_ops_time: 175.6   landing_coord: (1.0067, 0.6535)  epsilon: 0.0\n",
      "episode: 941   score: -231.2741   time_steps: 126  landing_ops_time: 134.2   landing_coord: (1.0014, 0.3522)  epsilon: 0.0\n",
      "episode: 942   score: -149.7914   time_steps: 77  landing_ops_time: 125.7   landing_coord: (-0.7237, -0.1687)  epsilon: 0.0\n",
      "episode: 943   score: -809.4329   time_steps: 420  landing_ops_time: 112.6   landing_coord: (0.0728, -0.0009)  epsilon: 0.0\n",
      "episode: 944   score: -127.6857   time_steps: 222  landing_ops_time: 148.3   landing_coord: (0.2843, -0.0329)  epsilon: 0.0\n",
      "episode: 945   score: -270.6369   time_steps: 104  landing_ops_time: 161.5   landing_coord: (1.0095, 0.4536)  epsilon: 0.0\n",
      "episode: 946   score: -750.0305   time_steps: 338  landing_ops_time: 151.8   landing_coord: (0.6417, 0.2073)  epsilon: 0.0\n",
      "episode: 947   score: -104.7554   time_steps: 195  landing_ops_time: 163.9   landing_coord: (-0.2296, -0.0111)  epsilon: 0.0\n",
      "episode: 948   score: -206.3485   time_steps: 248  landing_ops_time: 163.5   landing_coord: (0.5803, -0.076)  epsilon: 0.0\n",
      "episode: 949   score: -245.0936   time_steps: 117  landing_ops_time: 176.2   landing_coord: (1.01, 0.1223)  epsilon: 0.0\n",
      "episode: 950   score: -193.1362   time_steps: 290  landing_ops_time: 181.0   landing_coord: (0.3011, 0.0549)  epsilon: 0.0\n",
      "episode: 951   score: -228.0697   time_steps: 118  landing_ops_time: 193.7   landing_coord: (1.0062, 0.0492)  epsilon: 0.0\n",
      "episode: 952   score: -20.6362   time_steps: 70  landing_ops_time: 192.9   landing_coord: (0.2513, -0.0564)  epsilon: 0.0\n",
      "episode: 953   score: -128.3395   time_steps: 102  landing_ops_time: 192.2   landing_coord: (-1.0034, 0.3965)  epsilon: 0.0\n",
      "episode: 954   score: -408.3255   time_steps: 205  landing_ops_time: 160.4   landing_coord: (-0.6276, -0.0497)  epsilon: 0.0\n",
      "episode: 955   score: -248.5239   time_steps: 142  landing_ops_time: 158.7   landing_coord: (1.0061, 0.0287)  epsilon: 0.0\n",
      "episode: 956   score: -221.7255   time_steps: 128  landing_ops_time: 162.5   landing_coord: (1.0094, 0.1306)  epsilon: 0.0\n",
      "episode: 957   score: -282.4048   time_steps: 92  landing_ops_time: 141.5   landing_coord: (1.0174, 0.0146)  epsilon: 0.0\n",
      "episode: 958   score: -240.9254   time_steps: 101  landing_ops_time: 131.2   landing_coord: (1.0058, 0.1158)  epsilon: 0.0\n",
      "episode: 959   score: -288.6568   time_steps: 194  landing_ops_time: 116.5   landing_coord: (-0.7062, -0.0633)  epsilon: 0.0\n",
      "episode: 960   score: -253.7952   time_steps: 117  landing_ops_time: 124.2   landing_coord: (1.0041, -0.0522)  epsilon: 0.0\n",
      "episode: 961   score: -90.4185   time_steps: 81  landing_ops_time: 106.9   landing_coord: (-0.7027, 0.1972)  epsilon: 0.0\n",
      "episode: 962   score: -232.1649   time_steps: 120  landing_ops_time: 103.2   landing_coord: (0.8518, 0.1791)  epsilon: 0.0\n",
      "episode: 963   score: -111.6772   time_steps: 85  landing_ops_time: 108.2   landing_coord: (0.6411, -0.1715)  epsilon: 0.0\n",
      "episode: 964   score: -304.1229   time_steps: 128  landing_ops_time: 106.5   landing_coord: (1.0056, -0.074)  epsilon: 0.0\n",
      "episode: 965   score: -314.9517   time_steps: 129  landing_ops_time: 98.8   landing_coord: (1.0153, 0.0654)  epsilon: 0.0\n",
      "episode: 966   score: -428.2601   time_steps: 215  landing_ops_time: 97.5   landing_coord: (-0.368, 0.0763)  epsilon: 0.0\n",
      "episode: 967   score: -95.7907   time_steps: 204  landing_ops_time: 106.2   landing_coord: (-0.1013, -0.043)  epsilon: 0.0\n",
      "episode: 968   score: -256.5801   time_steps: 93  landing_ops_time: 117.4   landing_coord: (1.0123, 0.0196)  epsilon: 0.0\n",
      "episode: 969   score: -113.0271   time_steps: 102  landing_ops_time: 116.6   landing_coord: (-0.6365, -0.1712)  epsilon: 0.0\n",
      "episode: 970   score: -141.0945   time_steps: 227  landing_ops_time: 107.4   landing_coord: (0.0879, -0.0428)  epsilon: 0.0\n",
      "episode: 971   score: -885.8579   time_steps: 451  landing_ops_time: 118.4   landing_coord: (0.4374, -0.0903)  epsilon: 0.0\n",
      "episode: 972   score: -59.0999   time_steps: 164  landing_ops_time: 155.4   landing_coord: (-0.388, -0.0041)  epsilon: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 973   score: -292.4656   time_steps: 98  landing_ops_time: 159.8   landing_coord: (1.0166, 0.0208)  epsilon: 0.0\n",
      "episode: 974   score: -45.5007   time_steps: 209  landing_ops_time: 161.1   landing_coord: (-0.2856, -0.0395)  epsilon: 0.0\n",
      "episode: 975   score: -152.7276   time_steps: 101  landing_ops_time: 169.2   landing_coord: (0.6813, 0.098)  epsilon: 0.0\n",
      "episode: 976   score: -61.1413   time_steps: 237  landing_ops_time: 166.4   landing_coord: (-0.065, -0.0335)  epsilon: 0.0\n",
      "episode: 977   score: -3.4195   time_steps: 168  landing_ops_time: 168.6   landing_coord: (-0.2087, -0.0403)  epsilon: 0.0\n",
      "episode: 978   score: 25.9444   time_steps: 320  landing_ops_time: 165.0   landing_coord: (-0.0753, -0.0009)  epsilon: 0.0\n",
      "episode: 979   score: -90.4857   time_steps: 131  landing_ops_time: 187.7   landing_coord: (0.619, 0.0307)  epsilon: 0.0\n",
      "episode: 980   score: -101.5585   time_steps: 69  landing_ops_time: 190.6   landing_coord: (-0.6514, 0.1684)  epsilon: 0.0\n",
      "episode: 981   score: -69.2655   time_steps: 227  landing_ops_time: 174.8   landing_coord: (0.0055, -0.0427)  epsilon: 0.0\n",
      "episode: 982   score: -34.7131   time_steps: 146  landing_ops_time: 152.4   landing_coord: (-0.3316, 0.0666)  epsilon: 0.0\n",
      "episode: 983   score: -44.6896   time_steps: 207  landing_ops_time: 150.6   landing_coord: (-0.202, -0.03)  epsilon: 0.0\n",
      "episode: 984   score: -345.7403   time_steps: 162  landing_ops_time: 161.5   landing_coord: (0.915, 0.0197)  epsilon: 0.0\n",
      "episode: 985   score: -203.4943   time_steps: 175  landing_ops_time: 156.8   landing_coord: (1.0023, 0.1353)  epsilon: 0.0\n",
      "episode: 986   score: -107.1373   time_steps: 130  landing_ops_time: 164.2   landing_coord: (1.0054, 0.083)  epsilon: 0.0\n",
      "episode: 987   score: -18.0861   time_steps: 165  landing_ops_time: 153.5   landing_coord: (-0.2662, -0.054)  epsilon: 0.0\n",
      "episode: 988   score: -92.4823   time_steps: 85  landing_ops_time: 153.2   landing_coord: (-0.473, 0.0338)  epsilon: 0.0\n",
      "episode: 989   score: -47.6499   time_steps: 150  landing_ops_time: 129.7   landing_coord: (-0.243, -0.0076)  epsilon: 0.0\n",
      "episode: 990   score: -246.4049   time_steps: 112  landing_ops_time: 131.6   landing_coord: (0.8657, 0.1168)  epsilon: 0.0\n",
      "episode: 991   score: -153.5531   time_steps: 87  landing_ops_time: 135.9   landing_coord: (0.6905, -0.0101)  epsilon: 0.0\n",
      "episode: 992   score: -186.755   time_steps: 100  landing_ops_time: 121.9   landing_coord: (0.7571, -0.0354)  epsilon: 0.0\n",
      "episode: 993   score: -163.4447   time_steps: 83  landing_ops_time: 117.3   landing_coord: (-0.7157, -0.2074)  epsilon: 0.0\n",
      "episode: 994   score: -78.7314   time_steps: 99  landing_ops_time: 104.9   landing_coord: (0.545, 0.1241)  epsilon: 0.0\n",
      "episode: 995   score: -1897.2687   time_steps: 597  landing_ops_time: 98.6   landing_coord: (0.1569, 0.0063)  epsilon: 0.0\n",
      "episode: 996   score: -906.8165   time_steps: 446  landing_ops_time: 140.8   landing_coord: (0.8283, 0.0243)  epsilon: 0.0\n",
      "episode: 997   score: -119.7961   time_steps: 78  landing_ops_time: 172.4   landing_coord: (-0.6202, 0.0821)  epsilon: 0.0\n",
      "episode: 998   score: -3418.2154   time_steps: 827  landing_ops_time: 163.7   landing_coord: (0.1122, -0.0009)  epsilon: 0.0\n",
      "episode: 999   score: -112.8766   time_steps: 120  landing_ops_time: 237.9   landing_coord: (0.6936, -0.2055)  epsilon: 0.0\n",
      "episode: 1000   score: -277.9951   time_steps: 195  landing_ops_time: 234.9   landing_coord: (-0.7466, -0.0087)  epsilon: 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "TODO:\n",
    "    1. Generate multiple epoisdes \n",
    "    2. At each timestep in a episode, store the sample <s, a, r, s',done> and save it in memory. Then, take a random batch\n",
    "    of batch size from the memory and train the network.\n",
    "    3. Take action according to the ε-greedy policy and go the next state. \n",
    "    4. Update the current Q-value network after every timestep in a episode.  \n",
    "    5. Update the target Q-value network to current Q-value network after training for a episode. This means that weights an\n",
    "    biases of target Q-value network will become same as current Q-value network.\n",
    "    \n",
    "Note: Penalty of -100 is added if an action make the episode end.\n",
    "    \n",
    "'''\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "      \n",
    "    \n",
    "    env = Monitor(gym.make('LunarLander-v2'), './video/',video_callable=lambda episode_id: True,force = True)\n",
    "    \n",
    "    # get size of state and action from environment\n",
    "    state_size = env.observation_space.shape[0]\n",
    "    action_size = env.action_space.n\n",
    "\n",
    "    agent = DQNAgent(state_size, action_size)\n",
    "\n",
    "    scores, episodes, time_step = [], [], []\n",
    "\n",
    "    for e in range(EPISODES+1):\n",
    "        done = False\n",
    "        score = 0\n",
    "        state = env.reset()\n",
    "        \n",
    "\n",
    "        state = np.reshape(state, [1, state_size])\n",
    "        time=1\n",
    "        landing_ops_time=0\n",
    "        \n",
    "        while not done:\n",
    "            if agent.render:\n",
    "                env.render()\n",
    "            time+=1\n",
    "            # get action for the current state and go one step in environment\n",
    "            action = agent.get_action(state)\n",
    "            if(time<30):\n",
    "                action=0\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            next_state = np.reshape(next_state, [1, state_size])\n",
    "            \n",
    "            if(time >300):\n",
    "                reward-=5\n",
    "            \n",
    "            \n",
    "            \n",
    "            if((len(time_step) >50)):\n",
    "                landing_ops_time=(np.mean(time_step[:-11:-1])-20)\n",
    "                if(time >landing_ops_time):\n",
    "\n",
    "                    if (next_state[0][3] - state[0][3] >0)  | (next_state[0][2] - state[0][2]>0) | (next_state[0][5] - state[0][5]>0):\n",
    "                        reward-=2\n",
    "                    else:\n",
    "                        reward+=2\n",
    "# ----                        \n",
    "\n",
    "#                     if ((next_state[0][0] <.02)|(next_state[0][1] <.02))|((next_state[0][0] >0.02)|(next_state[0][1] >0.02)) :\n",
    "#                         reward-=5\n",
    "#                     else:\n",
    "#                         reward+=5\n",
    "    #                 if(action !=0):\n",
    "    #                     reward-=3\n",
    "    #                 else:\n",
    "    #                     reward+=3\n",
    "\n",
    "            # if an action make the episode end, then gives penalty of -100\n",
    "#             reward = reward if not done or score == 200 else -100\n",
    "#             print(state)\n",
    "#             print(next_state)\n",
    "#             if (next_state[0][0] - state[0][0] >0)  & (next_state[0][1] - state[0][1]>0) :\n",
    "#                 reward-=3\n",
    "#             else:\n",
    "#                 reward+=3\n",
    "\n",
    "            \n",
    "            # save the sample <s, a, r, s'> to the replay memory\n",
    "            agent.append_sample(state, action, reward, next_state, done)\n",
    "            \n",
    "            # every time step do the training\n",
    "            agent.train_model()\n",
    "            \n",
    "            score += reward\n",
    "            state = next_state\n",
    "\n",
    "            if done:\n",
    "                # every episode update the target model to be same with model\n",
    "                agent.update_target_model()\n",
    "                time_step.append(time)\n",
    "\n",
    "                \n",
    "\n",
    "                if ((next_state[0][0] <-.02)|(next_state[0][1] <-.02))|((next_state[0][0] >0.02)|(next_state[0][1] >0.02)) :\n",
    "                    reward-=30\n",
    "                else:\n",
    "                    if (time <250) :\n",
    "                        reward+=70\n",
    "                scores.append(score)\n",
    "                episodes.append(e)\n",
    "                pylab.plot(episodes, scores, 'b')\n",
    "                pylab.savefig(\"./save_graph/cartpole_dqn.png\")\n",
    "                print(\"episode:\", e, \"  score:\", round(score,4), \"  time_steps:\",\n",
    "                      time,\" landing_ops_time:\",round(landing_ops_time,4) ,\"  landing_coord:\",(round(next_state[0][0],4),round(next_state[0][1],4)),\" epsilon:\", round(agent.epsilon,4))\n",
    "\n",
    "                # if the mean of scores of last 30 episode is bigger than 490\n",
    "                # stop training\n",
    "#                 if np.mean(scores[-min(30, len(scores)):]) > 490:\n",
    "                agent.model.save_weights(\"./save_model/cartpole_dqn.h5\")\n",
    "#                     sys.exit()\n",
    "        #save the model \n",
    "        if e % 50 == 0:\n",
    "            agent.model.save_weights(\"./save_model/cartpole_dqn.h5\")\n",
    "            \n",
    "env.close()       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 32)                288       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 1,476\n",
      "Trainable params: 1,476\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 32)                288       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 1,476\n",
      "Trainable params: 1,476\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Score is  -127.47691988345177\n"
     ]
    }
   ],
   "source": [
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.n\n",
    "agent = DQNAgent(state_size, action_size)\n",
    "score = 0\n",
    "state = env.reset()\n",
    "state = np.reshape(state, [1, state_size])\n",
    "done = False\n",
    "\n",
    "# Run the model for single episode\n",
    "while not done:\n",
    "    # env.render()\n",
    "    action = agent.get_action(state)\n",
    "    next_state, reward, done, info = env.step(action)\n",
    "    next_state = np.reshape(next_state, [1, state_size])\n",
    "    state = next_state\n",
    "    score += reward\n",
    "    \n",
    "print('Score is ', score)\n",
    "env.close()   \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the state vector consists of eight variables (in this order) between -1 and 1:\n",
    "\n",
    "# Lander position in x\n",
    "# Lander position in y\n",
    "# Lander velocity in x\n",
    "# Lander velocity in y\n",
    "# Lander angle\n",
    "# Lander angular velocity\n",
    "# Contact left landing leg\n",
    "# Contact right landing leg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-79dd11ab2b8c>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-79dd11ab2b8c>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    t[:-:-1]\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# t=[2,4,3,26,33,55,23,55,12]\n",
    "# t[:-:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
